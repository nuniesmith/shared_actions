name: üöÄ Unified Service Management

# Docker Network Configuration:
# This workflow sets up dedicated Docker networks with static IP ranges for each service:
# - FKS:   172.20.0.0/16 (containers: 172.20.1.0/24)
# - ATS:   172.21.0.0/16 (containers: 172.21.1.0/24)  
# - Nginx: 172.22.0.0/16 (containers: 172.22.1.0/24)
# 
# Benefits:
# - Predictable IP addresses for service communication
# - Proper iptables rules for inter-service traffic
# - Tailscale subnet advertisement for VPN access to all containers
# - Network isolation between services while allowing controlled communication

on:
  workflow_call:
    inputs:
      service_name:
        description: 'Name of the service to manage (e.g., fks, nginx, ats)'
        required: true
        type: string
      
      action_type:
        description: 'Action to perform'
        required: false
        type: string
        default: 'deploy'
        # Options: deploy, destroy, health-check, restart
      
      deployment_mode:
        description: 'Deployment mode'
        required: false
        type: string
        default: 'full-deploy'
        # Options: full-deploy, update-only, restart-only, code-only
      
      # üéØ New Options You Requested
      skip_tests:
        description: 'Skip running code tests'
        required: false
        type: boolean
        default: false
      
      skip_docker_build:
        description: 'Skip building Docker images'
        required: false
        type: boolean
        default: false
      
      build_docker_on_changes:
        description: 'Only build Docker if code/Dockerfile changed'
        required: false
        type: boolean
        default: true
      
      overwrite_server:
        description: 'Destroy and recreate Linode server'
        required: false
        type: boolean
        default: false
      
      # Server Configuration
      server_type:
        description: 'Linode server type'
        required: false
        type: string
        default: 'g6-standard-2'
      
      target_region:
        description: 'Linode region'
        required: false
        type: string
        default: 'ca-central'
      
      domain_suffix:
        description: 'Domain suffix (e.g., 7gram.xyz)'
        required: false
        type: string
        default: '7gram.xyz'
      
      custom_domains:
        description: 'Comma-separated list of custom domains for DNS updates (overrides defaults)'
        required: false
        type: string
        default: ''
      
      # Feature Toggles
      enable_backups:
        description: 'Enable Linode backups'
        required: false
        type: boolean
        default: false
      
      # Destroy Options (for destroy action)
      destroy_scope:
        description: 'What to destroy (for destroy action)'
        required: false
        type: string
        default: 'service-only'
      
      confirm_destruction:
        description: 'Type "DESTROY" to confirm destruction'
        required: false
        type: string

    secrets:
      # Core Infrastructure
      LINODE_CLI_TOKEN:
        required: true
      SERVICE_ROOT_PASSWORD:
        required: true
      
      # User Management
      JORDAN_PASSWORD:
        required: true
      ACTIONS_USER_PASSWORD:
        required: true
      
      # VPN & Networking
      TS_OAUTH_CLIENT_ID:
        description: 'Tailscale OAuth client ID'
        required: true
      TS_OAUTH_SECRET:
        description: 'Tailscale OAuth client secret'
        required: true
      TAILSCALE_TAILNET:
        description: 'Tailscale tailnet name (optional)'
        required: false
      
      # DNS Management (Optional)
      CLOUDFLARE_EMAIL:
        required: false
      CLOUDFLARE_API_TOKEN:
        required: false
      CLOUDFLARE_ZONE_ID:
        required: false
      
      # Container Registry (Optional)
      DOCKER_USERNAME:
        required: false
      DOCKER_TOKEN:
        required: false
      
      # Notifications (Optional)
      DISCORD_WEBHOOK:
        required: false

    outputs:
      # Infrastructure outputs
      server_ip:
        description: 'Public IP address of the deployed server'
        value: ${{ jobs.setup-infrastructure.outputs.server_ip }}
      server_id:
        description: 'Linode server ID'
        value: ${{ jobs.setup-infrastructure.outputs.server_id }}
      tailscale_ip:
        description: 'Tailscale IP address of the server'
        value: ${{ jobs.setup-infrastructure.outputs.tailscale_ip }}

  workflow_dispatch:
    inputs:
      service_name:
        description: 'Name of the service to manage'
        required: true
        type: choice
        options:
          - 'fks'
          - 'nginx'
          - 'ats'
          - 'custom'
      
      action_type:
        description: 'Action to perform'
        required: true
        type: choice
        options:
          - 'deploy'
          - 'destroy'
          - 'health-check'
          - 'restart'
        default: 'deploy'
      
      deployment_mode:
        description: 'Deployment mode (for deploy action)'
        required: false
        type: choice
        options:
          - 'full-deploy'
          - 'update-only'
          - 'restart-only'
          - 'code-only'
        default: 'full-deploy'
      
      # üéØ Your Requested Options
      skip_tests:
        description: 'Skip running code tests'
        required: false
        type: boolean
        default: false
      
      skip_docker_build:
        description: 'Skip building Docker images'
        required: false
        type: boolean
        default: false
      
      build_docker_on_changes:
        description: 'Only build Docker if code/Dockerfile changed'
        required: false
        type: boolean
        default: true
      
      overwrite_server:
        description: 'Destroy and recreate Linode server'
        required: false
        type: boolean
        default: false
      
      # Destroy Options (for destroy action)
      destroy_scope:
        description: 'What to destroy (for destroy action)'
        required: false
        type: choice
        options:
          - 'service-only'
          - 'full-server'
          - 'reset-service'
        default: 'service-only'
      
      confirm_destruction:
        description: 'Type "DESTROY" to confirm destruction'
        required: false
        type: string
      
      # Server Configuration
      server_type:
        description: 'Linode server type'
        required: false
        type: choice
        options:
          - 'g6-nanode-1'          # 1GB RAM
          - 'g6-standard-1'        # 2GB RAM
          - 'g6-standard-2'        # 4GB RAM
          - 'g6-standard-4'        # 8GB RAM
          - 'g6-standard-8'        # 16GB RAM
        default: 'g6-standard-2'

env:
  SERVICE_NAME: ${{ inputs.service_name }}
  ACTION_TYPE: ${{ inputs.action_type }}
  DEPLOYMENT_MODE: ${{ inputs.deployment_mode }}
  SERVER_TYPE: ${{ inputs.server_type }}
  TARGET_REGION: ${{ inputs.target_region || 'ca-central' }}
  DOMAIN_SUFFIX: ${{ inputs.domain_suffix || '7gram.xyz' }}
  FULL_DOMAIN: ${{ inputs.service_name }}.${{ inputs.domain_suffix || '7gram.xyz' }}
  
  # Your requested options
  SKIP_TESTS: ${{ inputs.skip_tests }}
  SKIP_DOCKER_BUILD: ${{ inputs.skip_docker_build }}
  BUILD_DOCKER_ON_CHANGES: ${{ inputs.build_docker_on_changes }}
  OVERWRITE_SERVER: ${{ inputs.overwrite_server }}

jobs:
  # ============================================================================
  # Pre-flight Checks & Validation
  # ============================================================================
  preflight-checks:
    name: üõ´ Pre-flight Checks
    runs-on: ubuntu-latest
    outputs:
      action_validated: ${{ steps.validate-action.outputs.validated }}
      should_destroy: ${{ steps.validate-action.outputs.should_destroy }}
      should_deploy: ${{ steps.validate-action.outputs.should_deploy }}
      should_health_check: ${{ steps.validate-action.outputs.should_health_check }}
      should_overwrite_server: ${{ steps.validate-action.outputs.should_overwrite_server }}
      destroy_confirmed: ${{ steps.validate-destroy.outputs.confirmed }}
      code_changed: ${{ steps.check-changes.outputs.code_changed }}
      docker_build_needed: ${{ steps.check-changes.outputs.docker_build_needed }}
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch full history for change detection

      - name: üéØ Validate Action Type
        id: validate-action
        run: |
          echo "üéØ Validating action: ${{ env.ACTION_TYPE }}"
          
          case "${{ env.ACTION_TYPE }}" in
            "deploy")
              echo "should_deploy=true" >> $GITHUB_OUTPUT
              echo "should_destroy=false" >> $GITHUB_OUTPUT
              echo "should_health_check=false" >> $GITHUB_OUTPUT
              ;;
            "destroy")
              echo "should_deploy=false" >> $GITHUB_OUTPUT
              echo "should_destroy=true" >> $GITHUB_OUTPUT
              echo "should_health_check=false" >> $GITHUB_OUTPUT
              ;;
            "health-check")
              echo "should_deploy=false" >> $GITHUB_OUTPUT
              echo "should_destroy=false" >> $GITHUB_OUTPUT
              echo "should_health_check=true" >> $GITHUB_OUTPUT
              ;;
            "restart")
              echo "should_deploy=true" >> $GITHUB_OUTPUT
              echo "should_destroy=false" >> $GITHUB_OUTPUT
              echo "should_health_check=false" >> $GITHUB_OUTPUT
              ;;
            *)
              echo "‚ùå Invalid action type: ${{ env.ACTION_TYPE }}"
              exit 1
              ;;
          esac
          
          # Check if server should be overwritten (force destroy when redeploying)
          echo "üîç Checking overwrite server setting: ${{ env.OVERWRITE_SERVER }}"
          if [[ "${{ env.OVERWRITE_SERVER }}" == "true" && ("${{ env.ACTION_TYPE }}" == "deploy" || "${{ env.ACTION_TYPE }}" == "restart") ]]; then
            echo "should_overwrite_server=true" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è Server will be overwritten (destroyed and recreated)"
          else
            echo "should_overwrite_server=false" >> $GITHUB_OUTPUT
            echo "‚ÑπÔ∏è Server will be created if not exists, or reused if exists"
          fi
          
          echo "validated=true" >> $GITHUB_OUTPUT

      - name: ‚ö†Ô∏è Validate Destruction Request
        id: validate-destroy
        if: steps.validate-action.outputs.should_destroy == 'true' || steps.validate-action.outputs.should_overwrite_server == 'true'
        run: |
          # For server overwrite during deployment, skip confirmation requirement
          if [[ "${{ steps.validate-action.outputs.should_overwrite_server }}" == "true" && "${{ env.ACTION_TYPE }}" == "deploy" ]]; then
            echo "‚úÖ Server overwrite confirmed (deploy mode)"
            echo "confirmed=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # For explicit destroy actions, require confirmation
          if [[ "${{ inputs.confirm_destruction }}" != "DESTROY" ]]; then
            echo "‚ùå Destruction not confirmed. You must type 'DESTROY' exactly."
            echo "confirmed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "‚úÖ Destruction confirmed for ${{ env.SERVICE_NAME }}"
          echo "confirmed=true" >> $GITHUB_OUTPUT

      - name: üîç Check for Code Changes
        id: check-changes
        if: steps.validate-action.outputs.should_deploy == 'true'
        run: |
          echo "üîç Checking for code and Docker changes..."
          
          # TEMPORARY: Force Docker builds for all services since DockerHub images were cleared
          echo "üîÑ FORCING Docker builds - DockerHub images were cleared"
          echo "code_changed=true" >> $GITHUB_OUTPUT
          echo "docker_build_needed=true" >> $GITHUB_OUTPUT
          
          # TODO: Re-enable change detection later by uncommenting the logic below
          # and removing the forced build logic above
          
          # Check if this is the first commit or if we should build anyway
          #if [[ $(git rev-list --count HEAD) -le 1 ]] || [[ "${{ env.BUILD_DOCKER_ON_CHANGES }}" == "false" ]]; then
          #  echo "First commit or change detection disabled - assuming changes exist"
          #  echo "code_changed=true" >> $GITHUB_OUTPUT
          #  echo "docker_build_needed=true" >> $GITHUB_OUTPUT
          #else
          #  # Check for changes in the last commit
          #  CHANGED_FILES=$(git diff --name-only HEAD~1 HEAD)
          #  echo "Changed files: $CHANGED_FILES"
          #  
          #  # Check if code files changed (exclude docs, configs, etc.)
          #  CODE_CHANGED="false"
          #  if echo "$CHANGED_FILES" | grep -E '\.(js|ts|py|go|java|cpp|c|rs|php)$' > /dev/null; then
          #    CODE_CHANGED="true"
          #    echo "‚úÖ Code files changed"
          #  fi
          #  
          #  # Check if Docker-related files changed
          #  DOCKER_BUILD_NEEDED="false"
          #  if echo "$CHANGED_FILES" | grep -E '(Dockerfile|docker-compose|requirements|package\.json|go\.mod|Cargo\.toml)' > /dev/null; then
          #    DOCKER_BUILD_NEEDED="true"
          #    echo "‚úÖ Docker-related files changed"
          #  fi
          #  
          #  # If build_docker_on_changes is true, only build if changes detected
          #  if [[ "${{ env.BUILD_DOCKER_ON_CHANGES }}" == "true" ]]; then
          #    if [[ "$CODE_CHANGED" == "true" || "$DOCKER_BUILD_NEEDED" == "true" ]]; then
          #      DOCKER_BUILD_NEEDED="true"
          #    else
          #      DOCKER_BUILD_NEEDED="false"
          #      echo "‚ÑπÔ∏è No relevant changes detected - skipping Docker build"
          #    fi
          #  fi
          #  
          #  echo "code_changed=$CODE_CHANGED" >> $GITHUB_OUTPUT
          #  echo "docker_build_needed=$DOCKER_BUILD_NEEDED" >> $GITHUB_OUTPUT
          #fi

      - name: üîê Validate Secrets
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
          SERVICE_ROOT_PASSWORD: ${{ secrets.SERVICE_ROOT_PASSWORD }}
          JORDAN_PASSWORD: ${{ secrets.JORDAN_PASSWORD }}
          ACTIONS_USER_PASSWORD: ${{ secrets.ACTIONS_USER_PASSWORD }}
          TS_OAUTH_CLIENT_ID: ${{ secrets.TS_OAUTH_CLIENT_ID }}
          TS_OAUTH_SECRET: ${{ secrets.TS_OAUTH_SECRET }}
          # SSL-related secrets (optional for nginx)
          CLOUDFLARE_EMAIL: ${{ secrets.CLOUDFLARE_EMAIL }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "üîê Validating required secrets..."
          
          MISSING_SECRETS=()
          [[ -z "$LINODE_CLI_TOKEN" ]] && MISSING_SECRETS+=("LINODE_CLI_TOKEN")
          [[ -z "$SERVICE_ROOT_PASSWORD" ]] && MISSING_SECRETS+=("SERVICE_ROOT_PASSWORD")
          [[ -z "$JORDAN_PASSWORD" ]] && MISSING_SECRETS+=("JORDAN_PASSWORD")
          [[ -z "$ACTIONS_USER_PASSWORD" ]] && MISSING_SECRETS+=("ACTIONS_USER_PASSWORD")
          [[ -z "$TS_OAUTH_CLIENT_ID" ]] && MISSING_SECRETS+=("TS_OAUTH_CLIENT_ID")
          [[ -z "$TS_OAUTH_SECRET" ]] && MISSING_SECRETS+=("TS_OAUTH_SECRET")
          
          if [[ ${#MISSING_SECRETS[@]} -gt 0 ]]; then
            echo "‚ùå Missing required secrets:"
            printf '  - %s\n' "${MISSING_SECRETS[@]}"
            exit 1
          fi
          
          echo "‚úÖ All required secrets validated"
          
          # Check SSL-related secrets for nginx deployments
          if [[ "${{ env.SERVICE_NAME }}" == "nginx" ]]; then
            SSL_SECRETS=()
            [[ -z "$CLOUDFLARE_EMAIL" ]] && SSL_SECRETS+=("CLOUDFLARE_EMAIL")
            [[ -z "$CLOUDFLARE_API_TOKEN" ]] && SSL_SECRETS+=("CLOUDFLARE_API_TOKEN")
            
            if [[ ${#SSL_SECRETS[@]} -gt 0 ]]; then
              echo "‚ö†Ô∏è SSL secrets missing (will use HTTP challenge or self-signed):"
              printf '  - %s\n' "${SSL_SECRETS[@]}"
              echo "üí° For wildcard certificates and better reliability, add:"
              echo "   - CLOUDFLARE_EMAIL (your Cloudflare account email)"
              echo "   - CLOUDFLARE_API_TOKEN (Cloudflare API token with DNS edit permissions)"
            else
              echo "‚úÖ SSL secrets available for DNS-01 challenge"
            fi
          fi

  # ============================================================================
  # Resource Cleanup (Optional, runs before deployment)
  # ============================================================================
  cleanup-old-resources:
    name: üßπ Cleanup Old Resources
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: preflight-checks
    if: |
      needs.preflight-checks.outputs.should_deploy == 'true' && 
      (github.event_name == 'push' || inputs.overwrite_server == true)
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üîó Set up Tailscale
        uses: tailscale/github-action@v3
        with:
          oauth-client-id: ${{ secrets.TS_OAUTH_CLIENT_ID }}
          oauth-secret: ${{ secrets.TS_OAUTH_SECRET }}
          tags: tag:ci

      - name: üì¶ Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: üßπ Cleanup Tailscale and Linode Resources
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
          TS_OAUTH_CLIENT_ID: ${{ secrets.TS_OAUTH_CLIENT_ID }}
          TS_OAUTH_SECRET: ${{ secrets.TS_OAUTH_SECRET }}
          TAILSCALE_TAILNET: ${{ secrets.TAILSCALE_TAILNET }}
        run: |
          echo "üßπ Cleaning up old ${{ env.SERVICE_NAME }} resources..."
          
          # Get Tailscale access token using OAuth with better error handling
          echo "üîë Getting Tailscale access token..."
          
          # First, test the OAuth request and capture the full response
          OAUTH_RESPONSE=$(curl -s -X POST https://api.tailscale.com/api/v2/oauth/token \
            -H "Content-Type: application/x-www-form-urlencoded" \
            -d "grant_type=client_credentials" \
            -d "client_id=$TS_OAUTH_CLIENT_ID" \
            -d "client_secret=$TS_OAUTH_SECRET" 2>/dev/null || echo "CURL_FAILED")
          
          echo "üîç OAuth response preview: ${OAUTH_RESPONSE:0:100}..."
          
          if [[ "$OAUTH_RESPONSE" == "CURL_FAILED" ]]; then
            echo "‚ùå OAuth request failed completely"
            echo "üîç Checking OAuth credentials..."
            echo "  Client ID length: ${#TS_OAUTH_CLIENT_ID}"
            echo "  Client secret length: ${#TS_OAUTH_SECRET}"
            exit 1
          fi
          
          # Try to parse the token, with error handling
          TOKEN=$(echo "$OAUTH_RESPONSE" | jq -r '.access_token // empty' 2>/dev/null || echo "")
          
          if [[ -z "$TOKEN" || "$TOKEN" == "null" || "$TOKEN" == "empty" ]]; then
            echo "‚ùå Failed to get valid access token"
            echo "üîç OAuth response: $OAUTH_RESPONSE"
            
            # Check if it's an error response
            ERROR_MSG=$(echo "$OAUTH_RESPONSE" | jq -r '.error_description // .error // empty' 2>/dev/null || echo "")
            if [[ -n "$ERROR_MSG" ]]; then
              echo "üîç OAuth error: $ERROR_MSG"
            fi
            
            echo "‚ö†Ô∏è Skipping Tailscale cleanup due to OAuth issues"
            echo "üí° Please check your TS_OAUTH_CLIENT_ID and TS_OAUTH_SECRET secrets"
          else
            echo "‚úÖ Successfully obtained access token"
            
            # Function to clean up Tailscale devices by hostname pattern
            cleanup_tailscale_devices() {
              local hostname_pattern="$1"
              local cleanup_reason="${2:-old server cleanup}"
              
              echo "üîó Tailscale cleanup for pattern: $hostname_pattern ($cleanup_reason)"
              
              # Use OAuth token and correct tailnet reference
              TAILNET="${TAILSCALE_TAILNET:-"-"}"
              
              DEVICES_RESPONSE=$(curl -s "https://api.tailscale.com/api/v2/tailnet/$TAILNET/devices" \
                -H "Authorization: Bearer $TOKEN" \
                -H "Accept: application/json" 2>/dev/null || echo '{"devices":[]}')
              
              # Validate response before processing
              if ! echo "$DEVICES_RESPONSE" | jq empty 2>/dev/null; then
                echo "‚ö†Ô∏è Invalid JSON response from Tailscale API, skipping cleanup"
                return 0
              fi
              
              MATCHING_DEVICES=$(echo "$DEVICES_RESPONSE" | jq -r --arg pattern "$hostname_pattern" '
                .devices[]? | 
                select(
                  (.name | test("^" + $pattern + "(-[0-9]+)?$")) or
                  (.name == $pattern) or
                  (.hostname | test("^" + $pattern + "(-[0-9]+)?$")) or
                  (.hostname == $pattern)
                ) | 
                .id' 2>/dev/null || echo "")
              
              local removed_count=0
              if [[ -n "$MATCHING_DEVICES" ]]; then
                for device_id in $MATCHING_DEVICES; do
                  if [[ -n "$device_id" && "$device_id" != "null" ]]; then
                    echo "üóëÔ∏è Removing Tailscale device: $device_id"
                    RESPONSE=$(curl -s -X DELETE "https://api.tailscale.com/api/v2/device/$device_id" \
                      -H "Authorization: Bearer $TOKEN" \
                      -w "HTTP_STATUS:%{http_code}" 2>/dev/null)
                    
                    HTTP_STATUS=$(echo "$RESPONSE" | grep -o "HTTP_STATUS:[0-9]*" | cut -d: -f2)
                    if [[ "$HTTP_STATUS" == "200" || "$HTTP_STATUS" == "204" ]]; then
                      echo "‚úÖ Removed Tailscale device $device_id"
                      removed_count=$((removed_count + 1))
                    else
                      echo "‚ö†Ô∏è Failed to remove device $device_id (HTTP $HTTP_STATUS)"
                    fi
                  fi
                  sleep 1
                done
              fi
              
              if [[ $removed_count -gt 0 ]]; then
                echo "‚úÖ $hostname_pattern cleanup completed - removed $removed_count devices"
              else
                echo "‚ÑπÔ∏è No $hostname_pattern devices found to remove"
              fi
              
              return 0
            }
            
            # Perform cleanup
            cleanup_tailscale_devices "${{ env.SERVICE_NAME }}" "pre-deployment cleanup" || {
              echo "‚ö†Ô∏è Cleanup function failed, but continuing deployment..."
            }
          fi
          
          # Linode cleanup for old servers
          if [[ -n "$LINODE_CLI_TOKEN" ]]; then
            echo "üñ•Ô∏è Cleaning up old Linode servers..."
            
            # Install linode-cli
            pip install linode-cli
            
            # Configure linode-cli
            echo "[DEFAULT]
          token = $LINODE_CLI_TOKEN" > ~/.linode-cli
            
            # Remove old service servers
            echo "üîç Looking for old ${{ env.SERVICE_NAME }} servers..."
            OLD_SERVERS=$(linode-cli linodes list --json | jq -r --arg service "${{ env.SERVICE_NAME }}" '.[] | select(.label | startswith($service)) | "\(.id):\(.label)"')
            
            for server_entry in $OLD_SERVERS; do
              if [[ -n "$server_entry" && "$server_entry" != ":" ]]; then
                server_id="${server_entry%%:*}"
                server_label="${server_entry#*:}"
                
                echo "üóëÔ∏è Removing old server: $server_id ($server_label)"
                linode-cli linodes delete "$server_id" --json || echo "‚ö†Ô∏è Failed to remove server $server_id"
                sleep 10
              fi
            done
          else
            echo "‚ö†Ô∏è Linode CLI token not available"
          fi
          
          echo "‚úÖ Cleanup completed for ${{ env.SERVICE_NAME }}"

  # ============================================================================
  # Infrastructure Setup
  # ============================================================================

  # ============================================================================
  # Code Testing (Optional)
  # ============================================================================
  run-tests:
    name: üß™ Run Tests
    runs-on: ubuntu-latest
    needs: [preflight-checks, cleanup-old-resources]
    if: |
      always() &&
      needs.preflight-checks.outputs.should_deploy == 'true' && 
      inputs.skip_tests == false &&
      (needs.cleanup-old-resources.result == 'success' || needs.cleanup-old-resources.result == 'skipped')
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üß™ Auto-detect and Run Tests
        run: |
          echo "üß™ Auto-detecting test framework..."
          
          # Node.js/JavaScript tests
          if [[ -f "package.json" ]]; then
            echo "üì¶ Node.js project detected"
            if command -v npm &> /dev/null; then
              echo "Installing dependencies..."
              npm install
              
              if npm run test --if-present; then
                echo "‚úÖ Node.js tests passed"
              else
                echo "‚ö†Ô∏è Node.js tests failed or no test script found"
              fi
            fi
          fi
          
          # Python tests
          if [[ -f "requirements.txt" ]] || [[ -f "pyproject.toml" ]] || [[ -f "setup.py" ]]; then
            echo "üêç Python project detected"
            if command -v python3 &> /dev/null; then
              if [[ -f "requirements.txt" ]]; then
                pip install -r requirements.txt
              fi
              
              # Try different test runners
              if python -m pytest --version &> /dev/null && find . -name "*test*.py" | grep -q .; then
                echo "Running pytest..."
                python -m pytest
              elif python -m unittest discover -s . -p "*test*.py" 2>/dev/null; then
                echo "‚úÖ Python unittest tests passed"
              else
                echo "‚ÑπÔ∏è No Python tests found or test framework not available"
              fi
            fi
          fi
          
          # Go tests
          if [[ -f "go.mod" ]]; then
            echo "üî∑ Go project detected"
            if command -v go &> /dev/null; then
              go test ./...
              echo "‚úÖ Go tests passed"
            fi
          fi
          
          echo "‚úÖ Test phase complete"

  # ============================================================================
  # Docker Build (Conditional)
  # ============================================================================
  build-docker-api:
    name: üê≥ Build API Docker Images
    runs-on: ubuntu-latest
    needs: [preflight-checks, cleanup-old-resources, run-tests]
    if: |
      always() && 
      needs.preflight-checks.outputs.should_deploy == 'true' && 
      inputs.skip_docker_build == false && 
      needs.preflight-checks.outputs.docker_build_needed == 'true' &&
      (needs.cleanup-old-resources.result == 'success' || needs.cleanup-old-resources.result == 'skipped') &&
      (needs.run-tests.result == 'success' || needs.run-tests.result == 'skipped')
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üîë Login to Docker Hub
        env:
          DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
          DOCKER_TOKEN: ${{ secrets.DOCKER_TOKEN }}
        if: env.DOCKER_USERNAME != '' && env.DOCKER_TOKEN != ''
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_TOKEN }}

      - name: üê≥ Build and Push API Docker Images
        run: |
          echo "üê≥ Building API Docker images for ${{ env.SERVICE_NAME }}..."
          
          # Build API services (Python servers: api, worker, data)
          API_SERVICES=()
          
          # Check for API service configuration
          if [[ -f "docker-compose.api.yml" ]]; then
            echo "üìã Found docker-compose.api.yml - building API services"
            docker compose -f docker-compose.api.yml build
            
            if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
              echo "üì§ Pushing API compose images..."
              docker compose -f docker-compose.api.yml push || echo "‚ö†Ô∏è Some API images may not have push configured"
            fi
          elif [[ -f "docker-compose.yml" ]]; then
            # Build only API-related services from main compose file
            echo "üìã Building API services from main docker-compose.yml"
            
            # Extract API service names (common patterns: api, worker, data, backend)
            API_SERVICES=($(docker compose config --services 2>/dev/null | grep -E '^(api|worker|data|backend|server)$' || true))
            
            if [[ ${#API_SERVICES[@]} -gt 0 ]]; then
              echo "üîç Found API services: ${API_SERVICES[*]}"
              
              for service in "${API_SERVICES[@]}"; do
                echo "üê≥ Building service: $service"
                docker compose build "$service"
                
                if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
                  echo "üì§ Pushing service: $service"
                  docker compose push "$service" || echo "‚ö†Ô∏è Failed to push $service"
                fi
              done
            else
              echo "‚ÑπÔ∏è No API services found in docker-compose.yml"
            fi
          elif [[ -f "Dockerfile" ]]; then
            # Single Dockerfile - assume it's for API if service name suggests it
            if [[ "${{ env.SERVICE_NAME }}" =~ (api|backend|server) ]]; then
              echo "üìã Found Dockerfile - building as API service"
              
              IMAGE_TAG="${{ secrets.DOCKER_USERNAME }}/${{ env.SERVICE_NAME }}-api:latest"
              
              docker build -t "$IMAGE_TAG" .
              
              if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
                echo "üì§ Pushing image: $IMAGE_TAG"
                docker push "$IMAGE_TAG"
              fi
            else
              echo "‚ÑπÔ∏è Service doesn't appear to be API-focused - skipping API build"
            fi
          else
            echo "‚ÑπÔ∏è No Docker configuration found for API services"
          fi
          
          echo "‚úÖ API Docker build complete"

  build-docker-web:
    name: üåê Build Web Docker Images  
    runs-on: ubuntu-latest
    needs: [preflight-checks, cleanup-old-resources, run-tests]
    if: |
      always() && 
      needs.preflight-checks.outputs.should_deploy == 'true' && 
      inputs.skip_docker_build == false && 
      needs.preflight-checks.outputs.docker_build_needed == 'true' &&
      (needs.cleanup-old-resources.result == 'success' || needs.cleanup-old-resources.result == 'skipped') &&
      (needs.run-tests.result == 'success' || needs.run-tests.result == 'skipped')
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üîë Login to Docker Hub
        env:
          DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
          DOCKER_TOKEN: ${{ secrets.DOCKER_TOKEN }}
        if: env.DOCKER_USERNAME != '' && env.DOCKER_TOKEN != ''
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_TOKEN }}

      - name: üåê Build and Push Web Docker Images
        run: |
          echo "üåê Building Web Docker images for ${{ env.SERVICE_NAME }}..."
          
          # Build Web services (React web interface, frontend)
          WEB_SERVICES=()
          
          # Check for Web service configuration
          if [[ -f "docker-compose.web.yml" ]]; then
            echo "üìã Found docker-compose.web.yml - building Web services"
            docker compose -f docker-compose.web.yml build
            
            if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
              echo "üì§ Pushing Web compose images..."
              docker compose -f docker-compose.web.yml push || echo "‚ö†Ô∏è Some Web images may not have push configured"
            fi
          elif [[ -f "docker-compose.yml" ]]; then
            # Build only Web-related services from main compose file
            echo "üìã Building Web services from main docker-compose.yml"
            
            # Extract Web service names (common patterns: web, frontend, ui, client)
            WEB_SERVICES=($(docker compose config --services 2>/dev/null | grep -E '^(web|frontend|ui|client|app)$' || true))
            
            if [[ ${#WEB_SERVICES[@]} -gt 0 ]]; then
              echo "üîç Found Web services: ${WEB_SERVICES[*]}"
              
              for service in "${WEB_SERVICES[@]}"; do
                echo "üåê Building service: $service"
                docker compose build "$service"
                
                if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
                  echo "üì§ Pushing service: $service"
                  docker compose push "$service" || echo "‚ö†Ô∏è Failed to push $service"
                fi
              done
            else
              echo "‚ÑπÔ∏è No Web services found in docker-compose.yml"
            fi
          elif [[ -f "Dockerfile" ]]; then
            # Single Dockerfile - assume it's for Web if service name suggests it
            if [[ "${{ env.SERVICE_NAME }}" =~ (web|frontend|ui|client) ]]; then
              echo "üìã Found Dockerfile - building as Web service"
              
              IMAGE_TAG="${{ secrets.DOCKER_USERNAME }}/${{ env.SERVICE_NAME }}-web:latest"
              
              docker build -t "$IMAGE_TAG" .
              
              if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
                echo "üì§ Pushing image: $IMAGE_TAG"
                docker push "$IMAGE_TAG"
              fi
            else
              echo "‚ÑπÔ∏è Service doesn't appear to be Web-focused - skipping Web build"
            fi
          else
            echo "‚ÑπÔ∏è No Docker configuration found for Web services"
          fi
          
          echo "‚úÖ Web Docker build complete"

  build-docker-auth:
    name: üîê Build Auth Docker Images
    runs-on: ubuntu-latest
    needs: [preflight-checks, cleanup-old-resources, run-tests]
    if: |
      always() && 
      needs.preflight-checks.outputs.should_deploy == 'true' && 
      inputs.skip_docker_build == false && 
      needs.preflight-checks.outputs.docker_build_needed == 'true' &&
      (needs.cleanup-old-resources.result == 'success' || needs.cleanup-old-resources.result == 'skipped') &&
      (needs.run-tests.result == 'success' || needs.run-tests.result == 'skipped')
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üîë Login to Docker Hub
        env:
          DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
          DOCKER_TOKEN: ${{ secrets.DOCKER_TOKEN }}
        if: env.DOCKER_USERNAME != '' && env.DOCKER_TOKEN != ''
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_TOKEN }}

      - name: üîê Build and Push Auth Docker Images
        run: |
          echo "üîê Building Auth Docker images for ${{ env.SERVICE_NAME }}..."
          
          # Build Auth services (Authentication, authorization services)
          AUTH_SERVICES=()
          
          # Check for Auth service configuration
          if [[ -f "docker-compose.auth.yml" ]]; then
            echo "üìã Found docker-compose.auth.yml - building Auth services"
            docker compose -f docker-compose.auth.yml build
            
            if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
              echo "üì§ Pushing Auth compose images..."
              docker compose -f docker-compose.auth.yml push || echo "‚ö†Ô∏è Some Auth images may not have push configured"
            fi
          elif [[ -f "docker-compose.yml" ]]; then
            # Build only Auth-related services from main compose file
            echo "üìã Building Auth services from main docker-compose.yml"
            
            # Extract Auth service names (common patterns: auth, oauth, keycloak, etc.)
            AUTH_SERVICES=($(docker compose config --services 2>/dev/null | grep -E '^(auth|oauth|keycloak|identity|session)$' || true))
            
            if [[ ${#AUTH_SERVICES[@]} -gt 0 ]]; then
              echo "üîç Found Auth services: ${AUTH_SERVICES[*]}"
              
              for service in "${AUTH_SERVICES[@]}"; do
                echo "üîê Building service: $service"
                docker compose build "$service"
                
                if [[ -n "${{ secrets.DOCKER_USERNAME }}" ]]; then
                  echo "üì§ Pushing service: $service"
                  docker compose push "$service" || echo "‚ö†Ô∏è Failed to push $service"
                fi
              done
            else
              echo "‚ÑπÔ∏è No Auth services found in docker-compose.yml - may use external auth services"
            fi
          else
            echo "‚ÑπÔ∏è No custom Auth services to build - likely using external authentication"
          fi
          
          echo "‚úÖ Auth Docker build complete (or skipped if no custom services)"

  # ============================================================================
  # Server Destruction (if overwrite requested)
  # ============================================================================
  destroy-existing-server:
    name: üí• Destroy Existing Server
    runs-on: ubuntu-latest
    needs: [preflight-checks, cleanup-old-resources, build-docker-api, build-docker-web, build-docker-auth]
    if: |
      always() && 
      needs.preflight-checks.outputs.should_overwrite_server == 'true' &&
      needs.preflight-checks.outputs.destroy_confirmed == 'true' &&
      (needs.cleanup-old-resources.result == 'success' || needs.cleanup-old-resources.result == 'skipped') &&
      (needs.build-docker-api.result == 'success' || needs.build-docker-api.result == 'skipped') &&
      (needs.build-docker-web.result == 'success' || needs.build-docker-web.result == 'skipped') &&
      (needs.build-docker-auth.result == 'success' || needs.build-docker-auth.result == 'skipped')
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üîß Setup Linode CLI
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
        run: |
          pip install linode-cli
          # Configure via environment variable to avoid config file issues
          export LINODE_CLI_TOKEN="${{ secrets.LINODE_CLI_TOKEN }}"
          # Test CLI access
          linode-cli --version

      - name: üßπ Cleanup Services Before Destruction
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
          TS_OAUTH_CLIENT_ID: ${{ secrets.TS_OAUTH_CLIENT_ID }}
          TS_OAUTH_SECRET: ${{ secrets.TS_OAUTH_SECRET }}
          TAILSCALE_TAILNET: ${{ secrets.TAILSCALE_TAILNET }}
        run: |
          echo "üßπ Cleaning up external service registrations..."
          
          # Install dependencies
          sudo apt-get update && sudo apt-get install -y curl jq sshpass >/dev/null 2>&1 || true
          
          # Find existing server
          EXISTING_SERVER=$(linode-cli linodes list --text --no-headers | grep "${{ env.SERVICE_NAME }}" | head -1)
          
          if [[ -n "$EXISTING_SERVER" ]]; then
            SERVER_ID=$(echo "$EXISTING_SERVER" | cut -f1)
            SERVER_LABEL=$(echo "$EXISTING_SERVER" | cut -f2)
            
            # Try to get server IP for cleanup
            SERVER_INFO=$(linode-cli linodes view "$SERVER_ID" --text --no-headers)
            SERVER_IP_COL4=$(echo "$SERVER_INFO" | cut -f4)
            SERVER_IP_COL5=$(echo "$SERVER_INFO" | cut -f5)
            SERVER_IP_COL6=$(echo "$SERVER_INFO" | cut -f6)
            SERVER_IP_COL7=$(echo "$SERVER_INFO" | cut -f7)
            
            SERVER_IP=""
            for IP in "$SERVER_IP_COL4" "$SERVER_IP_COL5" "$SERVER_IP_COL6" "$SERVER_IP_COL7"; do
              if [[ "$IP" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
                SERVER_IP="$IP"
                break
              fi
            done
            
            if [[ -n "$SERVER_IP" ]]; then
              echo "üîç Found server to cleanup: $SERVER_LABEL ($SERVER_IP)"
              
              # Try to connect using password authentication for cleanup
              echo "üîó Attempting cleanup connection via password auth..."
              
              # Try to connect and cleanup using root password
              if timeout 30 sshpass -p "${{ secrets.SERVICE_ROOT_PASSWORD }}" ssh -o StrictHostKeyChecking=no -o ConnectTimeout=10 root@$SERVER_IP "echo 'Cleanup connection successful'" 2>/dev/null; then
                echo "üîó Connected to server for cleanup..."
                
                # Cleanup Tailscale device
                echo "üßπ Removing Tailscale device from network..."
                sshpass -p "${{ secrets.SERVICE_ROOT_PASSWORD }}" ssh -o StrictHostKeyChecking=no root@$SERVER_IP "tailscale logout 2>/dev/null || true" || true
                
                # Get device info before cleanup
                DEVICE_NAME=$(sshpass -p "${{ secrets.SERVICE_ROOT_PASSWORD }}" ssh -o StrictHostKeyChecking=no root@$SERVER_IP "hostname 2>/dev/null || echo '${{ env.SERVICE_NAME }}'" || echo "${{ env.SERVICE_NAME }}")
                echo "Device name for cleanup: $DEVICE_NAME"
                
                echo "‚úÖ Service cleanup completed"
              else
                echo "‚ö†Ô∏è Could not connect to server for cleanup (server may be down, password changed, or SSH not configured)"
                echo "‚ÑπÔ∏è This is normal if the server was already destroyed or is not responding"
              fi
            else
              echo "‚ö†Ô∏è Could not determine server IP for cleanup"
            fi
            
            # Cleanup Tailscale devices via API (more reliable and comprehensive)
            if [[ -n "$TS_OAUTH_CLIENT_ID" && -n "$TS_OAUTH_SECRET" ]]; then
              echo "üîó Comprehensive Tailscale cleanup for service ${{ env.SERVICE_NAME }} using OAuth..."
              
              # Get OAuth access token
              echo "üîë Getting OAuth access token for cleanup..."
              OAUTH_RESPONSE=$(curl -s -X POST https://api.tailscale.com/api/v2/oauth/token \
                -H "Content-Type: application/x-www-form-urlencoded" \
                -d "grant_type=client_credentials" \
                -d "client_id=$TS_OAUTH_CLIENT_ID" \
                -d "client_secret=$TS_OAUTH_SECRET" 2>/dev/null || echo "CURL_FAILED")
              
              if [[ "$OAUTH_RESPONSE" == "CURL_FAILED" ]]; then
                echo "‚ùå OAuth request failed for cleanup"
                echo "‚ö†Ô∏è Skipping Tailscale cleanup due to OAuth issues"
              else
                TOKEN=$(echo "$OAUTH_RESPONSE" | jq -r '.access_token // empty' 2>/dev/null || echo "")
                
                if [[ -z "$TOKEN" || "$TOKEN" == "null" || "$TOKEN" == "empty" ]]; then
                  echo "‚ùå Failed to get valid access token for cleanup"
                  echo "üîç OAuth response: $OAUTH_RESPONSE"
                  echo "‚ö†Ô∏è Skipping Tailscale cleanup due to OAuth token issues"
                else
                  echo "‚úÖ Successfully obtained OAuth access token for cleanup"
                  
                  # Simplified Tailscale cleanup
                  TAILNET="${TAILSCALE_TAILNET:-"-"}"
                  if [[ "$TAILNET" == "-" ]]; then
                    DEVICES_URL="https://api.tailscale.com/api/v2/devices"
                  else
                    DEVICES_URL="https://api.tailscale.com/api/v2/tailnet/$TAILNET/devices"
                  fi
                  
                  echo "üîó Fetching devices for cleanup..."
                  DEVICES_RESPONSE=$(curl -s -H "Authorization: Bearer $TOKEN" "$DEVICES_URL" 2>/dev/null || echo "CURL_FAILED")
                  
                  if [[ "$DEVICES_RESPONSE" != "CURL_FAILED" ]] && echo "$DEVICES_RESPONSE" | jq -e '.devices' >/dev/null 2>&1; then
                    # Find devices matching service name
                    CLEANUP_DEVICES=$(echo "$DEVICES_RESPONSE" | jq -r --arg service "${{ env.SERVICE_NAME }}" '
                      .devices[]? | 
                      select((.hostname // .name | test($service; "i"))) | 
                      .id // empty' | grep -v '^$' || true)
                    
                    if [[ -n "$CLEANUP_DEVICES" ]]; then
                      echo "üóëÔ∏è Cleaning up Tailscale devices:"
                      for device_id in $CLEANUP_DEVICES; do
                        echo "  Removing device: $device_id"
                        curl -s -X DELETE -H "Authorization: Bearer $TOKEN" \
                          "https://api.tailscale.com/api/v2/device/$device_id" >/dev/null 2>&1 || true
                        sleep 1
                      done
                      echo "‚úÖ Tailscale cleanup completed"
                    else
                      echo "‚ÑπÔ∏è No ${{ env.SERVICE_NAME }} devices found for cleanup"
                    fi
                  else
                    echo "‚ö†Ô∏è Could not retrieve Tailscale devices for cleanup"
                  fi
                fi
              fi
                    local hostname_pattern="$1"
                    local cleanup_reason="${2:-old server cleanup}"
                    
                    echo "ÔøΩ Tailscale cleanup for pattern: $hostname_pattern ($cleanup_reason)"
                    
                    # Use OAuth token and correct tailnet reference
                    TAILNET="${TAILSCALE_TAILNET:-"-"}"
                    
                    if [[ "$TAILNET" == "-" ]]; then
                      DEVICES_URL="https://api.tailscale.com/api/v2/devices"
                    else
                      DEVICES_URL="https://api.tailscale.com/api/v2/tailnet/$TAILNET/devices"
                    fi
                    
                    DEVICES_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" \
                      -H "Authorization: Bearer $TOKEN" \
                      -H "Accept: application/json" \
                      "$DEVICES_URL" 2>/dev/null || echo "CURL_FAILED")
                    
                    # Extract HTTP status code
                    HTTP_CODE=$(echo "$DEVICES_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                    DEVICES_JSON=$(echo "$DEVICES_RESPONSE" | sed '/HTTP_CODE:/d')
                    
                    echo "üîç API Response Code: $HTTP_CODE"
                    
                    # Validate response before processing
                    if [[ "$HTTP_CODE" == "200" ]] && echo "$DEVICES_JSON" | jq -e '.devices' >/dev/null 2>&1; then
                      echo "‚úÖ Devices API accessible, but cleanup simplified"
                    fi
                  fi
                fi
              fi
            else
              echo "‚ö†Ô∏è Tailscale API key not available"
            fi
          else
            echo "‚ÑπÔ∏è No existing server found for cleanup"
          fi

      - name: üí• Destroy Existing Server
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
        run: |
          echo "üí• Looking for existing ${{ env.SERVICE_NAME }} server to destroy..."
          
          # Find existing server
          EXISTING_SERVER=$(linode-cli linodes list --text --no-headers | grep "${{ env.SERVICE_NAME }}" | head -1)
          
          if [[ -n "$EXISTING_SERVER" ]]; then
            SERVER_ID=$(echo "$EXISTING_SERVER" | cut -f1)
            SERVER_LABEL=$(echo "$EXISTING_SERVER" | cut -f2)
            
            echo "üî• Destroying server: $SERVER_LABEL (ID: $SERVER_ID)"
            linode-cli linodes delete "$SERVER_ID"
            
            echo "‚è≥ Waiting for server destruction to complete..."
            sleep 30
            
            echo "‚úÖ Server destroyed successfully"
          else
            echo "‚ÑπÔ∏è No existing ${{ env.SERVICE_NAME }} server found to destroy"
            echo "‚úÖ Proceeding with fresh deployment"
          fi

  # ============================================================================
  # Main Destroy Job (for destroy action)
  # ============================================================================
  destroy-service:
    name: üóëÔ∏è Destroy Service
    runs-on: ubuntu-latest
    needs: preflight-checks
    if: needs.preflight-checks.outputs.should_destroy == 'true' && needs.preflight-checks.outputs.destroy_confirmed == 'true'
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üîß Setup Linode CLI
        if: inputs.destroy_scope == 'full-server'
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
        run: |
          pip install linode-cli
          # Configure via environment variable to avoid config file issues
          export LINODE_CLI_TOKEN="${{ secrets.LINODE_CLI_TOKEN }}"
          # Test CLI access
          linode-cli --version

      - name: üóëÔ∏è Execute Destruction
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
          TS_OAUTH_CLIENT_ID: ${{ secrets.TS_OAUTH_CLIENT_ID }}
          TS_OAUTH_SECRET: ${{ secrets.TS_OAUTH_SECRET }}
          TAILSCALE_TAILNET: ${{ secrets.TAILSCALE_TAILNET }}
        run: |
          echo "üóëÔ∏è Destroying ${{ env.SERVICE_NAME }}..."
          echo "Scope: ${{ inputs.destroy_scope }}"
          
          # Install dependencies for API calls
          sudo apt-get update && sudo apt-get install -y curl jq >/dev/null 2>&1 || true
          
          case "${{ inputs.destroy_scope }}" in
            "service-only")
              echo "üõë Stopping service containers only..."
              # Logic for service-only destruction
              ;;
            "reset-service")
              echo "üßπ Resetting service to clean state..."
              # Logic for service reset
              ;;
            "full-server")
              echo "üí• Destroying entire server with cleanup..."
              
              # Find and cleanup server before destruction
              SERVER_INFO=$(linode-cli linodes list --text --no-headers | grep "${{ env.SERVICE_NAME }}" | head -1)
              if [[ -n "$SERVER_INFO" ]]; then
                SERVER_ID=$(echo "$SERVER_INFO" | cut -f1)
                SERVER_LABEL=$(echo "$SERVER_INFO" | cut -f2)
                
                # Try to get server IP for cleanup
                SERVER_DETAILS=$(linode-cli linodes view "$SERVER_ID" --text --no-headers)
                SERVER_IP_COL4=$(echo "$SERVER_DETAILS" | cut -f4)
                SERVER_IP_COL5=$(echo "$SERVER_DETAILS" | cut -f5)
                SERVER_IP_COL6=$(echo "$SERVER_DETAILS" | cut -f6)
                SERVER_IP_COL7=$(echo "$SERVER_DETAILS" | cut -f7)
                
                SERVER_IP=""
                for IP in "$SERVER_IP_COL4" "$SERVER_IP_COL5" "$SERVER_IP_COL6" "$SERVER_IP_COL7"; do
                  if [[ "$IP" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
                    SERVER_IP="$IP"
                    break
                  fi
                done
                
                if [[ -n "$SERVER_IP" ]]; then
                  echo "üßπ Cleaning up services on server before destruction..."
                  
                  # Generate SSH key for cleanup
                  ssh-keygen -t rsa -b 4096 -f ~/.ssh/cleanup_key -N "" -C "cleanup-${{ env.SERVICE_NAME }}" || true
                  
                  # Try to connect and cleanup
                  if timeout 30 ssh -i ~/.ssh/cleanup_key -o StrictHostKeyChecking=no -o ConnectTimeout=10 root@$SERVER_IP "echo 'Cleanup connection successful'" 2>/dev/null; then
                    echo "üîó Connected for cleanup..."
                    
                    # Cleanup Tailscale
                    ssh -i ~/.ssh/cleanup_key -o StrictHostKeyChecking=no root@$SERVER_IP "tailscale logout || true" || true
                    
                    echo "‚úÖ Service cleanup completed"
                  else
                    echo "‚ö†Ô∏è Could not connect for cleanup"
                  fi
                fi
                
                echo "Destroying: $SERVER_LABEL (ID: $SERVER_ID)"
                linode-cli linodes delete "$SERVER_ID"
                echo "‚úÖ Server destroyed"
                
                # Cleanup Tailscale devices via API after server destruction (comprehensive)
                if [[ -n "$TS_OAUTH_CLIENT_ID" && -n "$TS_OAUTH_SECRET" ]]; then
                  echo "üîó Final comprehensive Tailscale cleanup for service ${{ env.SERVICE_NAME }} using OAuth..."
                  
                  # Get OAuth token for destruction cleanup
                  DESTROY_OAUTH_RESPONSE=$(curl -s -X POST https://api.tailscale.com/api/v2/oauth/token \
                    -H "Content-Type: application/x-www-form-urlencoded" \
                    -d "grant_type=client_credentials" \
                    -d "client_id=$TS_OAUTH_CLIENT_ID" \
                    -d "client_secret=$TS_OAUTH_SECRET" 2>/dev/null || echo "CURL_FAILED")
                  
                  if [[ "$DESTROY_OAUTH_RESPONSE" != "CURL_FAILED" ]]; then
                    DESTROY_TOKEN=$(echo "$DESTROY_OAUTH_RESPONSE" | jq -r '.access_token // empty' 2>/dev/null || echo "")
                    
                    if [[ -n "$DESTROY_TOKEN" && "$DESTROY_TOKEN" != "empty" ]]; then
                      TAILNET="${TAILSCALE_TAILNET:-"-"}"
                      if [[ "$TAILNET" == "-" ]]; then
                        echo "‚ö†Ô∏è Using default tailnet"
                        DEVICES_URL="https://api.tailscale.com/api/v2/devices"
                      else
                        echo "üîç Using tailnet: $TAILNET"
                        DEVICES_URL="https://api.tailscale.com/api/v2/tailnet/$TAILNET/devices"
                      fi
                      
                      echo "üåê Fetching ALL remaining devices for final cleanup..."
                      DEVICES_RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -H "Authorization: Bearer $DESTROY_TOKEN" "$DEVICES_URL" 2>/dev/null || echo "CURL_FAILED")
                      
                      # Extract HTTP status code
                      HTTP_CODE=$(echo "$DEVICES_RESPONSE" | grep "HTTP_CODE:" | cut -d: -f2)
                      DEVICES_JSON=$(echo "$DEVICES_RESPONSE" | sed '/HTTP_CODE:/d')
                      
                      echo "üîç API Response Code: $HTTP_CODE"
                      
                      if [[ "$HTTP_CODE" == "200" ]] && echo "$DEVICES_JSON" | jq -e '.devices' >/dev/null 2>&1; then
                        echo "üßπ Simplified Tailscale cleanup for service: ${{ env.SERVICE_NAME }}"
                        
                        # Find devices matching service name (simplified)
                        MATCHING_DEVICES=$(echo "$DEVICES_JSON" | jq -r --arg service "${{ env.SERVICE_NAME }}" '
                          .devices[]? | 
                          select(
                            (.hostname // .name | test($service; "i"))
                          ) | 
                          .id // empty' | grep -v '^$' || true)
                        
                        if [[ -n "$MATCHING_DEVICES" ]]; then
                          echo "Found devices to remove:"
                          REMOVAL_COUNT=0
                          for device_id in $MATCHING_DEVICES; do
                            if [[ -n "$device_id" ]]; then
                              DEVICE_INFO=$(echo "$DEVICES_JSON" | jq -r --arg id "$device_id" '.devices[]? | select(.id == $id) | "\(.hostname // .name // "unknown")"')
                              echo "  Removing: $device_id ($DEVICE_INFO)"
                              
                              DELETE_URL="https://api.tailscale.com/api/v2/device/$device_id"
                              curl -s -X DELETE -H "Authorization: Bearer $DESTROY_TOKEN" "$DELETE_URL" >/dev/null 2>&1 || true
                              ((REMOVAL_COUNT++))
                              sleep 1
                            fi
                          done
                          echo "‚úÖ Removed $REMOVAL_COUNT Tailscale devices"
                        else
                          echo "‚ÑπÔ∏è No matching Tailscale devices found"
                        fi
                  else
                    echo "‚ö†Ô∏è Could not retrieve Tailscale devices for cleanup - HTTP: $HTTP_CODE"
                  fi
                fi
              fi
            fi
          else
            echo "‚ö†Ô∏è No server found for ${{ env.SERVICE_NAME }}"
          fi
          ;;
          esac

  # ============================================================================
  # Server Infrastructure Setup
  # ============================================================================
  setup-infrastructure:
    name: üèóÔ∏è Setup Infrastructure
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [preflight-checks, cleanup-old-resources, destroy-existing-server, build-docker-api, build-docker-web, build-docker-auth]
    if: |
      always() && 
      needs.preflight-checks.outputs.should_deploy == 'true' &&
      (needs.cleanup-old-resources.result == 'success' || needs.cleanup-old-resources.result == 'skipped') &&
      (needs.destroy-existing-server.result == 'success' || needs.destroy-existing-server.result == 'skipped') &&
      (needs.build-docker-api.result == 'success' || needs.build-docker-api.result == 'skipped') &&
      (needs.build-docker-web.result == 'success' || needs.build-docker-web.result == 'skipped') &&
      (needs.build-docker-auth.result == 'success' || needs.build-docker-auth.result == 'skipped')
    outputs:
      server_ip: ${{ steps.create-server.outputs.server_ip }}
      server_id: ${{ steps.create-server.outputs.server_id }}
      tailscale_ip: ${{ steps.stage2-setup.outputs.tailscale_ip }}
      ssh_private_key: ${{ steps.create-server.outputs.ssh_private_key }}
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üîß Setup Linode CLI
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
        run: |
          pip install linode-cli
          # Configure via environment variable to avoid config file issues
          export LINODE_CLI_TOKEN="${{ secrets.LINODE_CLI_TOKEN }}"
          # Test CLI access
          linode-cli --version

      - name: üöÄ Create or Find Server
        id: create-server
        env:
          LINODE_CLI_TOKEN: ${{ secrets.LINODE_CLI_TOKEN }}
        run: |
          echo "üöÄ Managing Linode server for ${{ env.SERVICE_NAME }}..."
          
          # Check if server already exists (unless we just destroyed it)
          if [[ "${{ inputs.overwrite_server }}" != "true" ]]; then
            EXISTING_SERVER=$(linode-cli linodes list --text --no-headers | grep "${{ env.SERVICE_NAME }}" | head -1)
            if [[ -n "$EXISTING_SERVER" ]]; then
              echo "üîç Debug - Found existing server:"
              echo "$EXISTING_SERVER"
              
              SERVER_ID=$(echo "$EXISTING_SERVER" | cut -f1)
              # Try different columns for IP address
              SERVER_IP_COL4=$(echo "$EXISTING_SERVER" | cut -f4)
              SERVER_IP_COL5=$(echo "$EXISTING_SERVER" | cut -f5)
              SERVER_IP_COL6=$(echo "$EXISTING_SERVER" | cut -f6)
              SERVER_IP_COL7=$(echo "$EXISTING_SERVER" | cut -f7)
              
              echo "IP candidates: Col4='$SERVER_IP_COL4', Col5='$SERVER_IP_COL5', Col6='$SERVER_IP_COL6', Col7='$SERVER_IP_COL7'"
              
              # Use the first valid IP address we find
              for IP in "$SERVER_IP_COL4" "$SERVER_IP_COL5" "$SERVER_IP_COL6" "$SERVER_IP_COL7"; do
                if [[ "$IP" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
                  SERVER_IP="$IP"
                  break
                fi
              done
              
              if [[ -z "$SERVER_IP" ]]; then
                echo "‚ùå Could not extract IP address from server info"
                exit 1
              fi
              
              echo "‚úÖ Using existing server: $SERVER_IP (ID: $SERVER_ID)"
              echo "server_ip=$SERVER_IP" >> $GITHUB_OUTPUT
              echo "server_id=$SERVER_ID" >> $GITHUB_OUTPUT
              
              # Create a placeholder SSH key for consistency (will use password auth for existing servers)
              ssh-keygen -t rsa -b 4096 -f ~/.ssh/linode_deployment_key -N "" -C "github-actions-${{ env.SERVICE_NAME }}" 2>/dev/null || true
              SSH_PRIVATE_KEY=$(base64 -w 0 ~/.ssh/linode_deployment_key 2>/dev/null || echo "")
              echo "ssh_private_key=$SSH_PRIVATE_KEY" >> $GITHUB_OUTPUT
              
              exit 0
            fi
          fi
          
          # Create new server
          SERVER_LABEL="${{ env.SERVICE_NAME }}"
          echo "üÜï Creating new server: $SERVER_LABEL"
          
          # Generate SSH key for this deployment
          echo "üîë Generating SSH key for server access..."
          ssh-keygen -t rsa -b 4096 -f ~/.ssh/linode_deployment_key -N "" -C "github-actions-${{ env.SERVICE_NAME }}"
          
          # Get the public key content for server authorization
          SSH_PUBLIC_KEY=$(cat ~/.ssh/linode_deployment_key.pub)
          echo "üîë SSH Public Key: $SSH_PUBLIC_KEY"
          
          # Store the private key (base64 encoded for safe storage)
          SSH_PRIVATE_KEY=$(base64 -w 0 ~/.ssh/linode_deployment_key)
          echo "ssh_private_key=$SSH_PRIVATE_KEY" >> $GITHUB_OUTPUT
          
          echo "üöÄ Creating server with SSH key authentication..."
          echo "Using server type: ${{ env.SERVER_TYPE }}"
          echo "Using region: ${{ env.TARGET_REGION }}"
          echo "Using backup setting: ${{ inputs.enable_backups || 'false' }}"
          
          RESULT=$(linode-cli linodes create \
            --type "${{ env.SERVER_TYPE }}" \
            --region "${{ env.TARGET_REGION }}" \
            --image "linode/arch" \
            --label "$SERVER_LABEL" \
            --root_pass "${{ secrets.SERVICE_ROOT_PASSWORD }}" \
            --authorized_keys "$SSH_PUBLIC_KEY" \
            --backups_enabled=${{ inputs.enable_backups || 'false' }} \
            --text --no-headers)
          
          echo "üîç Server creation result:"
          echo "$RESULT"
          
          if [[ -z "$RESULT" ]] || [[ "$RESULT" == *"error"* ]] || [[ "$RESULT" == *"Error"* ]]; then
            echo "‚ùå Server creation failed!"
            echo "Result: $RESULT"
            exit 1
          fi
          
          SERVER_ID=$(echo "$RESULT" | cut -f1)
          
          if [[ -z "$SERVER_ID" ]] || [[ ! "$SERVER_ID" =~ ^[0-9]+$ ]]; then
            echo "‚ùå Invalid server ID extracted: '$SERVER_ID'"
            echo "Full result: $RESULT"
            exit 1
          fi
          
          echo "üÜî Server created with ID: $SERVER_ID"
          
          # Wait for server to be running
          echo "‚è≥ Waiting for server to be ready..."
          ATTEMPT=0
          while true; do
            # Get server info and check status
            SERVER_INFO=$(linode-cli linodes view "$SERVER_ID" --text --no-headers)
            
            # Debug: show the full output on first few attempts
            if [[ $ATTEMPT -lt 3 ]]; then
              echo "üîç Debug - Server info columns:"
              echo "$SERVER_INFO"
            fi
            
            # Status is in column 6 (ID|Label|Region|Type|Image|Status|IP|Backups)
            STATUS=$(echo "$SERVER_INFO" | cut -f6)
            
            echo "Attempt $((++ATTEMPT)): Status='$STATUS'"
            
            # Check if server is running
            if [[ "$STATUS" == "running" ]]; then
              echo "‚úÖ Server is running!"
              break
            fi
            
            # Don't wait forever for server status
            if [[ $ATTEMPT -gt 15 ]]; then
              echo "‚ö†Ô∏è Server status check timeout - proceeding to SSH test"
              break
            fi
            
            sleep 5  # Check more frequently
          done
          
          # Get server IP
          SERVER_INFO=$(linode-cli linodes view "$SERVER_ID" --text --no-headers)
          echo "üîç Debug - Server view output:"
          echo "$SERVER_INFO"
          
          # Try different columns for IP address
          SERVER_IP_COL4=$(echo "$SERVER_INFO" | cut -f4)
          SERVER_IP_COL5=$(echo "$SERVER_INFO" | cut -f5)
          SERVER_IP_COL6=$(echo "$SERVER_INFO" | cut -f6)
          SERVER_IP_COL7=$(echo "$SERVER_INFO" | cut -f7)
          
          echo "IP candidates: Col4='$SERVER_IP_COL4', Col5='$SERVER_IP_COL5', Col6='$SERVER_IP_COL6', Col7='$SERVER_IP_COL7'"
          
          # Use the first valid IP address we find
          for IP in "$SERVER_IP_COL4" "$SERVER_IP_COL5" "$SERVER_IP_COL6" "$SERVER_IP_COL7"; do
            if [[ "$IP" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
              SERVER_IP="$IP"
              break
            fi
          done
          
          if [[ -z "$SERVER_IP" ]]; then
            echo "‚ùå Could not extract IP address from server info"
            exit 1
          fi
          
          echo "‚úÖ Server ready: $SERVER_IP (ID: $SERVER_ID)"
          
          echo "server_ip=$SERVER_IP" >> $GITHUB_OUTPUT
          echo "server_id=$SERVER_ID" >> $GITHUB_OUTPUT

      - name: ‚è≥ Wait for SSH Access
        run: |
          echo "‚è≥ Waiting for SSH access to ${{ steps.create-server.outputs.server_ip }}..."
          
          SSH_READY=false
          
          # First, test basic connectivity
          echo "üîç Testing basic connectivity to port 22..."
          for i in {1..10}; do
            if timeout 5 nc -zv ${{ steps.create-server.outputs.server_ip }} 22 2>/dev/null; then
              echo "‚úÖ Port 22 is reachable on attempt $i"
              break
            fi
            echo "Port 22 not ready, waiting 10 seconds..."
            sleep 10
          done
          
          # Test SSH with detailed error output
          echo "üîë Testing SSH connection with private key..."
          
          for i in {1..15}; do
            echo "Attempt $i/15: Testing SSH connection..."
            
            # Use the generated private key for authentication
            SSH_OUTPUT=$(timeout 10 ssh -i ~/.ssh/linode_deployment_key -v -o StrictHostKeyChecking=no -o ConnectTimeout=5 -o ConnectionAttempts=1 \
               root@${{ steps.create-server.outputs.server_ip }} "echo 'SSH ready'" 2>&1 || echo "SSH_FAILED")
            
            if echo "$SSH_OUTPUT" | grep -q "SSH ready"; then
              echo "‚úÖ SSH ready after $i attempts"
              SSH_READY=true
              break
            else
              echo "SSH failed. Last few lines of output:"
              echo "$SSH_OUTPUT" | tail -3
            fi
            
            echo "Waiting 15 seconds before next attempt..."
            sleep 15
          done
          
          if [[ "$SSH_READY" != "true" ]]; then
            echo "‚ùå SSH failed to become ready after 30 attempts (5 minutes)"
            echo "üîç Debugging SSH connection..."
            
            # Try to get more info about why SSH is failing
            echo "Testing basic connectivity..."
            timeout 5 nc -zv ${{ steps.create-server.outputs.server_ip }} 22 || echo "Port 22 not reachable"
            
            exit 1
          fi

      - name: üèóÔ∏è Stage 1 - Pre-Reboot Setup
        id: stage1-setup
        env:
          TS_OAUTH_CLIENT_ID: ${{ secrets.TS_OAUTH_CLIENT_ID }}
          TS_OAUTH_SECRET: ${{ secrets.TS_OAUTH_SECRET }}
          TAILSCALE_TAILNET: ${{ secrets.TAILSCALE_TAILNET }}
          CLOUDFLARE_EMAIL: ${{ secrets.CLOUDFLARE_EMAIL }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          SERVICE_ROOT_PASSWORD: ${{ secrets.SERVICE_ROOT_PASSWORD }}
          ACTIONS_USER_PASSWORD: ${{ secrets.ACTIONS_USER_PASSWORD }}
          JORDAN_PASSWORD: ${{ secrets.JORDAN_PASSWORD }}
        run: |
          echo "üèóÔ∏è Stage 1: Pre-reboot foundation setup..."
          
          # Download and execute the stage 1 setup script
          curl -o stage1-setup.sh https://raw.githubusercontent.com/nuniesmith/actions/main/scripts/stage1-complete-setup.sh
          chmod +x stage1-setup.sh
          
          # Replace placeholders in setup script
          echo "üîÑ Replacing placeholders in stage1 setup script..."
          sed -i "s/SERVICE_NAME_PLACEHOLDER/${{ env.SERVICE_NAME }}/g" stage1-setup.sh
          sed -i "s/ACTIONS_USER_PASSWORD_PLACEHOLDER/${ACTIONS_USER_PASSWORD}/g" stage1-setup.sh
          sed -i "s/JORDAN_PASSWORD_PLACEHOLDER/${JORDAN_PASSWORD}/g" stage1-setup.sh
          
          # Create a new OAuth-based stage2 script
          echo "üîÑ Creating OAuth-based stage2 script..."
          cat > stage2-post-reboot.sh << 'EOF'
          #!/bin/bash
          set -euo pipefail
          
          echo "üöÄ Stage 2: Post-reboot setup starting..."
          
          # Configuration variables (to be replaced by workflow)
          TS_OAUTH_CLIENT_ID="${TS_OAUTH_CLIENT_ID}"
          TS_OAUTH_SECRET="${TS_OAUTH_SECRET}"
          TAILSCALE_TAILNET="${TAILSCALE_TAILNET:-"-"}"
          SERVICE_NAME="SERVICE_NAME_PLACEHOLDER"
          DOMAIN_NAME="DOMAIN_NAME_PLACEHOLDER"
          CLOUDFLARE_EMAIL="${CLOUDFLARE_EMAIL:-""}"
          CLOUDFLARE_API_TOKEN="${CLOUDFLARE_API_TOKEN:-""}"
          
          # Validate OAuth credentials
          if [[ -z "$TS_OAUTH_CLIENT_ID" ]]; then
            echo "‚ùå TS_OAUTH_CLIENT_ID is empty or not replaced"
            exit 1
          fi
          
          if [[ -z "$TS_OAUTH_SECRET" ]]; then
            echo "‚ùå TS_OAUTH_SECRET is empty or not replaced"
            exit 1
          fi
          
          echo "‚úÖ OAuth configuration loaded: SERVICE_NAME=$SERVICE_NAME"
          
          # Install required packages
          echo "üì¶ Installing required packages..."
          pacman -Rdd --noconfirm iptables 2>/dev/null || true
          pacman -S --noconfirm iptables-nft ufw jq curl || {
            echo "‚ö†Ô∏è Package installation failed, trying individually..."
            pacman -S --noconfirm iptables-nft || true
            pacman -S --noconfirm ufw || true
            pacman -S --noconfirm jq || true
            pacman -S --noconfirm curl || true
          }
          
          # Configure firewall
          echo "üî• Configuring firewall..."
          ufw --force reset
          ufw default deny incoming
          ufw default allow outgoing
          ufw allow ssh
          
          # Start Docker
          echo "üê≥ Starting Docker..."
          systemctl start docker
          
          # Wait for Docker
          for i in {1..10}; do
            if docker info >/dev/null 2>&1; then
              echo "‚úÖ Docker is ready"
              break
            fi
            sleep 5
          done
          
          # Create Docker network
          echo "üåê Creating Docker network for $SERVICE_NAME..."
          docker network rm ${SERVICE_NAME}-network 2>/dev/null || true
          
          case "$SERVICE_NAME" in
            "nginx")
              docker network create --driver bridge --subnet=172.22.0.0/16 nginx-network
              ;;
            "fks")
              docker network create --driver bridge --subnet=172.20.0.0/16 fks-network
              ;;
            "ats")
              docker network create --driver bridge --subnet=172.21.0.0/16 ats-network
              ;;
            *)
              docker network create --driver bridge --subnet=172.23.0.0/16 ${SERVICE_NAME}-network
              ;;
          esac
          
          # Start Tailscale
          echo "üîó Starting Tailscale with OAuth..."
          systemctl start tailscaled
          
          # Wait for tailscaled
          for i in {1..15}; do
            if systemctl is-active tailscaled >/dev/null 2>&1; then
              echo "‚úÖ Tailscaled daemon is active"
              break
            fi
            sleep 3
          done
          
          # Get OAuth token with better error handling
          echo "üîë Getting OAuth access token..."
          OAUTH_RESPONSE=$(curl -s -X POST https://api.tailscale.com/api/v2/oauth/token \
            -H "Content-Type: application/x-www-form-urlencoded" \
            -d "grant_type=client_credentials" \
            -d "client_id=$TS_OAUTH_CLIENT_ID" \
            -d "client_secret=$TS_OAUTH_SECRET" 2>/dev/null || echo "CURL_FAILED")
          
          if [[ "$OAUTH_RESPONSE" == "CURL_FAILED" ]]; then
            echo "‚ùå OAuth request failed completely"
            exit 1
          fi
          
          OAUTH_TOKEN=$(echo "$OAUTH_RESPONSE" | jq -r '.access_token // empty' 2>/dev/null || echo "")
          
          if [[ -z "$OAUTH_TOKEN" || "$OAUTH_TOKEN" == "null" || "$OAUTH_TOKEN" == "empty" ]]; then
            echo "‚ùå Failed to get OAuth access token"
            echo "üîç OAuth response: $OAUTH_RESPONSE"
            
            # Check for error details
            ERROR_MSG=$(echo "$OAUTH_RESPONSE" | jq -r '.error_description // .error // empty' 2>/dev/null || echo "")
            if [[ -n "$ERROR_MSG" ]]; then
              echo "üîç OAuth error: $ERROR_MSG"
            fi
            exit 1
          fi
          
          echo "‚úÖ OAuth token obtained successfully"
          
          # Create ephemeral auth key with improved error handling
          echo "üîë Creating ephemeral auth key..."
          TAILNET="${TAILSCALE_TAILNET:-"-"}"
          
          # Use correct tailnet reference for API
          if [[ "$TAILNET" == "-" ]]; then
            API_TAILNET="-"
          else
            API_TAILNET="$TAILNET"
          fi
          
          AUTH_KEY_RESPONSE=$(curl -s -X POST "https://api.tailscale.com/api/v2/tailnet/$API_TAILNET/keys" \
            -H "Authorization: Bearer $OAUTH_TOKEN" \
            -H "Content-Type: application/json" \
            -d '{"capabilities":{"devices":{"create":{"reusable":false,"ephemeral":true,"preauthorized":true,"tags":["tag:ci"]}}},"expirySeconds":3600}' 2>/dev/null || echo "CURL_FAILED")
          
          if [[ "$AUTH_KEY_RESPONSE" == "CURL_FAILED" ]]; then
            echo "‚ùå Auth key creation request failed"
            exit 1
          fi
          
          AUTH_KEY=$(echo "$AUTH_KEY_RESPONSE" | jq -r '.key // empty' 2>/dev/null || echo "")
          
          if [[ -z "$AUTH_KEY" || "$AUTH_KEY" == "empty" ]]; then
            echo "‚ùå Failed to create ephemeral auth key"
            echo "üîç Auth key response: $AUTH_KEY_RESPONSE"
            
            # Check for error details
            KEY_ERROR=$(echo "$AUTH_KEY_RESPONSE" | jq -r '.message // .error // empty' 2>/dev/null || echo "")
            if [[ -n "$KEY_ERROR" ]]; then
              echo "üîç Auth key error: $KEY_ERROR"
            fi
            exit 1
          fi
          
          echo "‚úÖ Ephemeral auth key created successfully"
          
          # Connect to Tailscale with better error handling and retries
          echo "üîó Connecting to Tailscale..."
          
          # Wait for tailscaled to be fully ready
          echo "‚è≥ Ensuring tailscaled is fully ready..."
          for i in {1..20}; do
            if systemctl is-active tailscaled >/dev/null 2>&1 && timeout 5 tailscale status >/dev/null 2>&1; then
              echo "‚úÖ Tailscaled daemon is fully ready"
              break
            fi
            if [[ $i -eq 20 ]]; then
              echo "‚ùå Tailscaled failed to become ready"
              systemctl status tailscaled --no-pager || true
              exit 1
            fi
            echo "Attempt $i/20: Waiting for tailscaled to be ready..."
            sleep 3
          done
          
          # Attempt Tailscale connection with retries
          CONNECTION_SUCCESS=false
          for attempt in {1..3}; do
            echo "üîó Tailscale connection attempt $attempt/3..."
            
            if timeout 300 tailscale up --authkey="$AUTH_KEY" --hostname="$SERVICE_NAME" --accept-routes --reset; then
              echo "‚úÖ Tailscale connected successfully on attempt $attempt"
              CONNECTION_SUCCESS=true
              break
            else
              echo "‚ùå Tailscale connection attempt $attempt failed"
              
              if [[ $attempt -lt 3 ]]; then
                echo "üîÑ Retrying in 10 seconds..."
                sleep 10
                
                # Logout and reset for clean retry
                tailscale logout 2>/dev/null || true
                sleep 5
              fi
            fi
          done
          
          if [[ "$CONNECTION_SUCCESS" != "true" ]]; then
            echo "‚ùå All Tailscale connection attempts failed"
            echo "üîç Tailscale status:"
            tailscale status || true
            echo "üîç Tailscale daemon logs:"
            journalctl -u tailscaled --no-pager -l --since='5 minutes ago' || true
            exit 1
          fi
          
          # Verify connection and get IP
          echo "üîç Verifying Tailscale connection..."
          for i in {1..10}; do
            TAILSCALE_IP=$(tailscale ip -4 2>/dev/null || echo "pending")
            if [[ "$TAILSCALE_IP" != "pending" && -n "$TAILSCALE_IP" ]]; then
              echo "‚úÖ Tailscale IP obtained: $TAILSCALE_IP"
              echo "$TAILSCALE_IP" > /tmp/tailscale_ip
              break
            fi
            echo "Attempt $i/10: Waiting for Tailscale IP..."
            sleep 3
          done
          
          if [[ "$TAILSCALE_IP" == "pending" || -z "$TAILSCALE_IP" ]]; then
            echo "‚ö†Ô∏è Could not get Tailscale IP, but connection may still work"
            echo "pending" > /tmp/tailscale_ip
          fi
          
          # Configure Tailscale subnet routing for Docker networks
          echo "üåê Configuring Tailscale subnet routing for Docker networks..."
          
          # Share Docker network subnets through Tailscale
          case "$SERVICE_NAME" in
            "nginx")
              echo "üîó Advertising nginx Docker network subnet: 172.22.0.0/16"
              tailscale up --advertise-routes=172.22.0.0/16 --accept-routes || {
                echo "‚ö†Ô∏è Failed to advertise nginx subnet, but continuing..."
              }
              ;;
            "fks")
              echo "üîó Advertising FKS Docker network subnet: 172.20.0.0/16"
              tailscale up --advertise-routes=172.20.0.0/16 --accept-routes || {
                echo "‚ö†Ô∏è Failed to advertise FKS subnet, but continuing..."
              }
              ;;
            "ats")
              echo "üîó Advertising ATS Docker network subnet: 172.21.0.0/16"
              tailscale up --advertise-routes=172.21.0.0/16 --accept-routes || {
                echo "‚ö†Ô∏è Failed to advertise ATS subnet, but continuing..."
              }
              ;;
            *)
              echo "üîó Advertising generic Docker network subnet: 172.23.0.0/16"
              tailscale up --advertise-routes=172.23.0.0/16 --accept-routes || {
                echo "‚ö†Ô∏è Failed to advertise ${SERVICE_NAME} subnet, but continuing..."
              }
              ;;
          esac
          
          # Enable IP forwarding for subnet routing
          echo "üì° Enabling IP forwarding for subnet routing..."
          echo 'net.ipv4.ip_forward = 1' >> /etc/sysctl.conf
          echo 'net.ipv6.conf.all.forwarding = 1' >> /etc/sysctl.conf
          sysctl -p
          
          # Complete firewall setup
          ufw allow in on tailscale0
          ufw --force enable
          
          echo "‚úÖ Stage 2 complete - server ready"
          EOF
          
          chmod +x stage2-post-reboot.sh
          
          # Replace placeholders in stage2 script
          echo "üîÑ Replacing placeholders in stage2 script..."
          
          # Debug: Show environment variables before replacement
          echo "üîç Debugging environment variables:"
          echo "TS_OAUTH_CLIENT_ID length: ${#TS_OAUTH_CLIENT_ID}"
          echo "TS_OAUTH_SECRET length: ${#TS_OAUTH_SECRET}"
          echo "TAILSCALE_TAILNET: ${TAILSCALE_TAILNET:-"(not set)"}"
          
          # Validate OAuth variables before replacement
          if [[ -z "$TS_OAUTH_CLIENT_ID" ]]; then
            echo "‚ùå TS_OAUTH_CLIENT_ID environment variable is empty!"
            exit 1
          fi
          
          if [[ -z "$TS_OAUTH_SECRET" ]]; then
            echo "‚ùå TS_OAUTH_SECRET environment variable is empty!"
            exit 1
          fi
          
          # Replace OAuth credentials using environment variable expansion  
          envsubst '${TS_OAUTH_CLIENT_ID} ${TS_OAUTH_SECRET} ${TAILSCALE_TAILNET} ${CLOUDFLARE_EMAIL} ${CLOUDFLARE_API_TOKEN}' < stage2-post-reboot.sh > stage2-post-reboot-temp.sh
          mv stage2-post-reboot-temp.sh stage2-post-reboot.sh
          
          # Replace service-specific variables
          sed -i "s|SERVICE_NAME_PLACEHOLDER|${{ env.SERVICE_NAME }}|g" stage2-post-reboot.sh
          sed -i "s|DOMAIN_NAME_PLACEHOLDER|${{ env.FULL_DOMAIN }}|g" stage2-post-reboot.sh
          
          # Debug: Show a few lines of the replaced script
          echo "üîç Sample of replaced script:"
          head -20 stage2-post-reboot.sh | grep -E "(TS_OAUTH|TAILSCALE)" || echo "No OAuth lines found in first 20 lines"
          
          # Verify OAuth credentials were replaced
          echo "üîç Verifying OAuth credential replacement..."
          
          # Count remaining placeholders
          PLACEHOLDER_COUNT=$(grep -c "PLACEHOLDER" stage2-post-reboot.sh || echo "0")
          echo "üìä Remaining placeholders: $PLACEHOLDER_COUNT"
          
          # Check for any template variables that weren't replaced (envsubst format)
          if grep -q '\${TS_OAUTH_CLIENT_ID}' stage2-post-reboot.sh; then
            echo "‚ùå OAuth template variables still exist in stage2 script!"
            echo "üîç Script preview (OAuth section):"
            grep -A 5 -B 5 "TS_OAUTH_CLIENT_ID" stage2-post-reboot.sh | head -10
            
            # Show environment variable status
            echo "üîç Environment variable status:"
            [[ -n "$TS_OAUTH_CLIENT_ID" ]] && echo "‚úÖ TS_OAUTH_CLIENT_ID is set (length: ${#TS_OAUTH_CLIENT_ID})" || echo "‚ùå TS_OAUTH_CLIENT_ID is empty"
            [[ -n "$TS_OAUTH_SECRET" ]] && echo "‚úÖ TS_OAUTH_SECRET is set (length: ${#TS_OAUTH_SECRET})" || echo "‚ùå TS_OAUTH_SECRET is empty"
            
            echo "‚ö†Ô∏è Continuing deployment - OAuth may fail but infrastructure will be set up"
          else
            echo "‚úÖ OAuth credentials successfully replaced in stage2 script"
          fi
          else
            echo "‚úÖ OAuth placeholders replaced successfully"
          fi
          
          # Upload scripts to server
          echo "üì§ Uploading scripts to server..."
          scp -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no stage1-setup.sh root@${{ steps.create-server.outputs.server_ip }}:/tmp/
          scp -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no stage2-post-reboot.sh root@${{ steps.create-server.outputs.server_ip }}:/usr/local/bin/
          
          # Execute stage 1 setup
          echo "üöÄ Executing stage1 setup..."
          ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "
            chmod +x /tmp/stage1-setup.sh
            chmod +x /usr/local/bin/stage2-post-reboot.sh
            /tmp/stage1-setup.sh
          "
          
          STAGE1_STATUS=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "cat /tmp/stage1_status" || echo "unknown")
          echo "stage1_status=$STAGE1_STATUS" >> $GITHUB_OUTPUT

      - name: üîÑ Reboot Server for Kernel Updates
        run: |
          echo "üîÑ Rebooting server for kernel updates and service initialization..."
          ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "reboot" || true
          
          echo "‚è≥ Waiting for server to come back online..."
          sleep 45  # Give more time for reboot
          
          # Wait for SSH to be available again
          for i in {1..20}; do
            if ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no -o ConnectTimeout=10 root@${{ steps.create-server.outputs.server_ip }} "echo 'SSH ready after reboot'"; then
              echo "‚úÖ Server is back online after reboot"
              break
            fi
            echo "Attempt $i/20: Waiting for server to come back online..."
            sleep 15
          done

      - name: üèóÔ∏è Stage 2 - Post-Reboot Verification
        id: stage2-setup
        run: |
          echo "üèóÔ∏è Stage 2: Verifying post-reboot setup..."
          
          # Wait for SSH to be available after reboot (servers take time to reboot)
          echo "‚è≥ Waiting for server to come back online after reboot..."
          SSH_READY=false
          
          for i in {1..20}; do
            echo "Attempt $i/20: Testing SSH connection after reboot..."
            
            if timeout 10 ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no -o ConnectTimeout=5 \
               root@${{ steps.create-server.outputs.server_ip }} "echo 'SSH ready after reboot'" 2>/dev/null; then
              echo "‚úÖ SSH ready after reboot (attempt $i)"
              SSH_READY=true
              break
            fi
            sleep 15  # Wait longer between attempts for reboot
          done
          
          if [[ "$SSH_READY" != "true" ]]; then
            echo "‚ùå SSH failed to become ready after reboot"
            exit 1
          fi
          
          # Debug: Check if stage2 service exists and was enabled
          echo "üîç Debugging stage2-setup.service status..."
          ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} "
            echo 'üìã Checking systemd service files:'
            ls -la /etc/systemd/system/stage2-setup.service || echo 'Service file not found'
            echo ''
            echo 'üìã Service file contents:'
            cat /etc/systemd/system/stage2-setup.service 2>/dev/null || echo 'Could not read service file'
            echo ''
            echo 'üìã Stage2 script exists:'
            ls -la /usr/local/bin/stage2-post-reboot.sh || echo 'Stage2 script not found'
            echo ''
            echo 'üìã Service enabled status:'
            systemctl is-enabled stage2-setup.service 2>/dev/null || echo 'Service not enabled'
            echo ''
            echo 'üìã Service status details:'
            systemctl status stage2-setup.service --no-pager 2>/dev/null || echo 'Service status unavailable'
            echo ''
            echo 'üìã Recent systemd logs:'
            journalctl -u stage2-setup.service --no-pager -l --since='10 minutes ago' 2>/dev/null || echo 'No logs available'
            echo ''
            echo 'üìã OAuth credential check in stage2 script:'
            grep -E '(TS_OAUTH|PLACEHOLDER)' /usr/local/bin/stage2-post-reboot.sh | head -5 || echo 'No OAuth lines found'
          " || true
          
          # Quick check if Tailscale is already working
          echo "üîç Quick Tailscale connectivity check..."
          QUICK_TAILSCALE_CHECK=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
            "timeout 10 tailscale status 2>/dev/null | grep -q 'Logged in' && echo 'connected' || echo 'checking'" || echo "checking")
          
          if [[ "$QUICK_TAILSCALE_CHECK" == "connected" ]]; then
            echo "‚úÖ Tailscale is already connected - skipping service wait"
            SKIP_SERVICE_WAIT=true
          else
            echo "‚è≥ Tailscale not yet ready - will monitor service completion"
            SKIP_SERVICE_WAIT=false
          fi
          
          # Wait for Stage 2 systemd service to complete (only if Tailscale not already connected)
          if [[ "$SKIP_SERVICE_WAIT" != "true" ]]; then
            echo "‚è≥ Waiting for stage2-setup.service to complete..."
            for i in {1..8}; do  # Reduced to 2 minutes (8 * 15s) since it's usually quick
              SERVICE_STATUS=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
                "systemctl is-active stage2-setup.service 2>/dev/null || echo 'inactive'")
              
              echo "Attempt $i/8: Stage 2 service status: $SERVICE_STATUS"
              
              # Check Tailscale status during wait
              TAILSCALE_READY=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
                "timeout 5 tailscale status 2>/dev/null | grep -q 'Logged in' && echo 'ready' || echo 'pending'" || echo "pending")
              
              if [[ "$TAILSCALE_READY" == "ready" ]]; then
                echo "‚úÖ Tailscale is connected - service completed successfully"
                break
              fi
              
              # For oneshot services: inactive means it completed (successfully or failed)
              if [[ "$SERVICE_STATUS" == "inactive" ]]; then
                # Check if it completed successfully
                EXIT_STATUS=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
                  "systemctl show stage2-setup.service --property=ExecMainStatus --value 2>/dev/null || echo 'unknown'")
                
                if [[ "$EXIT_STATUS" == "0" ]]; then
                  echo "‚úÖ Stage 2 service completed successfully"
                  break
                else
                  echo "‚ö†Ô∏è Stage 2 service completed with exit status: $EXIT_STATUS"
                  echo "üîç Checking if Tailscale connected anyway..."
                  FINAL_CHECK=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
                    "timeout 5 tailscale status 2>/dev/null | grep -q 'Logged in' && echo 'connected' || echo 'failed'")
                  
                  if [[ "$FINAL_CHECK" == "connected" ]]; then
                    echo "‚úÖ Tailscale is connected despite service exit status - continuing"
                    break
                  else
                    # Show logs for debugging
                    echo "üîç Stage 2 service logs:"
                    ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
                      "journalctl -u stage2-setup.service --no-pager -l --since='5 minutes ago'" || true
                    break
                  fi
                fi
              fi
              
              sleep 15
            done
          else
            echo "‚ö° Skipped service wait - Tailscale already operational"
          fi
          
          # Smart stage2 completion check
          echo "üîß Verifying deployment completion..."
          TAILSCALE_STATUS=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
            "timeout 10 tailscale status 2>/dev/null | grep -q 'Logged in' && echo 'connected' || echo 'not-connected'")
          
          if [[ "$TAILSCALE_STATUS" == "connected" ]]; then
            echo "‚úÖ Tailscale is connected and operational"
            
            # Quick verification of key services
            echo "üîç Verifying core services..."
            DOCKER_STATUS=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
              "systemctl is-active docker 2>/dev/null || echo 'inactive'")
            echo "Docker status: $DOCKER_STATUS"
            
            if [[ "$DOCKER_STATUS" == "active" ]]; then
              echo "‚úÖ All core services are operational"
            else
              echo "‚ö†Ô∏è Docker not active, but continuing since Tailscale is connected"
            fi
          else
            echo "‚ö†Ô∏è Tailscale not connected - attempting manual stage2 trigger..."
            
            # First, check if the script has OAuth credentials
            echo "üîç Checking OAuth credentials in stage2 script..."
            ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
              "if grep -q 'TS_OAUTH_CLIENT_ID_PLACEHOLDER' /usr/local/bin/stage2-post-reboot.sh; then
                 echo '‚ùå OAuth placeholders still exist in stage2 script'
                 echo 'üîç First few OAuth lines:'
                 grep -n 'TS_OAUTH' /usr/local/bin/stage2-post-reboot.sh | head -3
                 exit 1
               else
                 echo '‚úÖ OAuth placeholders appear to be replaced'
               fi" || {
                echo "‚ùå OAuth placeholder replacement failed - stage2 script is invalid"
                echo "This suggests the workflow placeholder replacement didn't work correctly"
                exit 1
              }
            
            # Manual execution with enhanced logging
            echo "üöÄ Executing stage2 script manually with enhanced logging..."
            ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
              "echo 'üîç Starting manual stage2 execution...'
               echo 'üìã Current environment:'
               echo 'PATH='\$PATH
               echo 'SHELL='\$SHELL
               echo ''
               echo 'üöÄ Executing stage2 script:'
               cd /
               timeout 300 bash -x /usr/local/bin/stage2-post-reboot.sh 2>&1 | tee /tmp/stage2_manual_output.log
               STAGE2_EXIT=\${PIPESTATUS[0]}
               echo ''
               echo 'üìä Stage2 manual execution completed with exit code: '\$STAGE2_EXIT
               echo 'üîç Last 10 lines of output:'
               tail -10 /tmp/stage2_manual_output.log
               exit \$STAGE2_EXIT" || {
                echo "‚ùå Manual stage2 execution failed"
                echo "üîç Getting detailed error information..."
                ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
                  "echo 'üìã Stage2 manual output (last 50 lines):'
                   tail -50 /tmp/stage2_manual_output.log 2>/dev/null || echo 'No output log found'
                   echo ''
                   echo 'üìã Systemd service logs:'
                   journalctl -u stage2-setup.service --no-pager -l --since='10 minutes ago'
                   echo ''
                   echo 'üìã Tailscaled status:'
                   systemctl status tailscaled --no-pager
                   echo ''
                   echo 'üìã Current Tailscale status:'
                   timeout 10 tailscale status || echo 'Tailscale status check failed'" || true
                echo "‚ö†Ô∏è Manual stage2 trigger failed, but continuing with deployment"
              }
            
            # Recheck after manual trigger
            TAILSCALE_STATUS=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
              "timeout 10 tailscale status 2>/dev/null | grep -q 'Logged in' && echo 'connected' || echo 'not-connected'")
            
            if [[ "$TAILSCALE_STATUS" == "connected" ]]; then
              echo "‚úÖ Manual trigger successful - Tailscale now connected"
            else
              echo "‚ùå Manual trigger failed - Tailscale still not connected"
            fi
          fi
          
          # Get Tailscale IP (multiple methods)
          TAILSCALE_IP=$(ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
            "tailscale ip -4 2>/dev/null || cat /tmp/tailscale_ip 2>/dev/null || echo 'pending'")
          echo "üîó Tailscale IP: $TAILSCALE_IP"
          echo "tailscale_ip=$TAILSCALE_IP" >> $GITHUB_OUTPUT
          
          # Verify essential services
          echo "üîç Verifying essential services..."
          ssh -i ~/.ssh/linode_deployment_key -o StrictHostKeyChecking=no root@${{ steps.create-server.outputs.server_ip }} \
            "systemctl is-active docker && echo '‚úÖ Docker is active'" || echo "‚ö†Ô∏è Docker may not be active"
          
  # ============================================================================
  # Deploy Service Application  
  # ============================================================================
  deploy-service:
    name: üöÄ Deploy Service
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [preflight-checks, setup-infrastructure]
    if: |
      always() && 
      needs.preflight-checks.outputs.should_deploy == 'true' &&
      needs.setup-infrastructure.result == 'success'
    
    steps:
      - name: üì• Checkout repository
        uses: actions/checkout@v4

      - name: üöÄ Deploy Service to Server
        run: |
          echo "üöÄ Deploying ${{ env.SERVICE_NAME }} service..."
          echo "Server IP: ${{ needs.setup-infrastructure.outputs.server_ip }}"
          echo "Tailscale IP: ${{ needs.setup-infrastructure.outputs.tailscale_ip }}"
          
          # Debug: Check if SSH key output exists
          if [[ -z "${{ needs.setup-infrastructure.outputs.ssh_private_key }}" ]]; then
            echo "‚ùå SSH private key output is empty"
            echo "üîç Available outputs from setup-infrastructure:"
            echo "  server_ip: ${{ needs.setup-infrastructure.outputs.server_ip }}"
            echo "  server_id: ${{ needs.setup-infrastructure.outputs.server_id }}"
            echo "  tailscale_ip: ${{ needs.setup-infrastructure.outputs.tailscale_ip }}"
            exit 1
          fi
          
          # Ensure .ssh directory exists and decode SSH private key for deployment
          mkdir -p ~/.ssh
          echo "${{ needs.setup-infrastructure.outputs.ssh_private_key }}" | base64 -d > ~/.ssh/deployment_key
          chmod 600 ~/.ssh/deployment_key
          
          # Verify the key was created successfully
          if [[ ! -f ~/.ssh/deployment_key ]]; then
            echo "‚ùå Failed to create SSH deployment key"
            exit 1
          fi
          echo "‚úÖ SSH deployment key created successfully"
          
          # Clone service repository to server
          echo "üì• Cloning ${{ env.SERVICE_NAME }} repository..."
          ssh -i ~/.ssh/deployment_key -o StrictHostKeyChecking=no root@${{ needs.setup-infrastructure.outputs.server_ip }} "
            # Ensure service user home directory exists
            mkdir -p /home/${{ env.SERVICE_NAME }}_user
            cd /home/${{ env.SERVICE_NAME }}_user
            
            # Remove existing repo if it exists for fresh clone
            if [[ -d '${{ env.SERVICE_NAME }}' ]]; then
              echo 'Removing existing ${{ env.SERVICE_NAME }} directory for fresh clone...'
              rm -rf ${{ env.SERVICE_NAME }}
            fi
            
            # Clone the service repository from nuniesmith/${{ env.SERVICE_NAME }}
            echo 'Cloning nuniesmith/${{ env.SERVICE_NAME }} repository...'
            if git clone https://github.com/nuniesmith/${{ env.SERVICE_NAME }}.git; then
              echo '‚úÖ Repository cloned successfully'
            else
              echo '‚ùå Repository clone failed!'
              exit 1
            fi
            
            cd ${{ env.SERVICE_NAME }}
            
            # Verify we have the essential files
            echo 'üîç Checking repository contents...'
            ls -la
            
            if [[ -f 'start.sh' ]]; then
              echo '‚úÖ Found start.sh - ready for deployment'
              chmod +x start.sh
            else
              echo '‚ö†Ô∏è start.sh not found in repository'
            fi
            
            if [[ -f 'docker-compose.yml' ]]; then
              echo '‚úÖ Found docker-compose.yml'
            else
              echo '‚ö†Ô∏è docker-compose.yml not found'
            fi
            
            # Set ownership to service user
            echo 'üë§ Setting ownership to service user...'
            chown -R ${{ env.SERVICE_NAME }}_user:${{ env.SERVICE_NAME }}_user /home/${{ env.SERVICE_NAME }}_user/${{ env.SERVICE_NAME }}
            
            echo '‚úÖ Repository setup completed'
          "
          
          # Deploy the service using start.sh as the primary method
          echo "üöÄ Starting nginx service deployment..."
          ssh -i ~/.ssh/deployment_key -o StrictHostKeyChecking=no root@${{ needs.setup-infrastructure.outputs.server_ip }} "
            cd /home/${{ env.SERVICE_NAME }}_user/${{ env.SERVICE_NAME }}
            
            echo 'üîç Current directory contents:'
            pwd
            ls -la
            
            # Run as the service user for proper permissions
            echo 'üé≠ Switching to service user for deployment...'
            
            # Use start.sh as the primary deployment method
            if [[ -f 'start.sh' ]]; then
              echo 'üöÄ Deploying with start.sh script...'
              chmod +x start.sh
              
              # Run start.sh as the service user
              su - ${{ env.SERVICE_NAME }}_user -c 'cd /home/${{ env.SERVICE_NAME }}_user/${{ env.SERVICE_NAME }} && ./start.sh'
              
              echo '‚úÖ start.sh deployment completed'
            elif [[ -f 'docker-compose.yml' ]]; then
              echo 'üê≥ Deploying with Docker Compose...'
              
              # Stop existing containers first
              docker-compose down 2>/dev/null || true
              
              # Clean up conflicting networks if they exist
              echo 'üßπ Cleaning up conflicting networks...'
              docker network rm ${{ env.SERVICE_NAME }}-network 2>/dev/null || true
              
              # Start services (docker-compose will create the network)
              docker-compose up -d
              
              echo '‚úÖ Docker Compose deployment completed'
            else
              echo '‚ùå No deployment method found (start.sh or docker-compose.yml missing)'
              echo 'üîç Available files:'
              ls -la
              exit 1
            fi
          "
          
          # Verify deployment
          echo "üîç Verifying service deployment..."
          DEPLOYMENT_SUCCESS=false
          for i in {1..5}; do
            if ssh -i ~/.ssh/deployment_key -o StrictHostKeyChecking=no root@${{ needs.setup-infrastructure.outputs.server_ip }} "docker ps | grep -q '${{ env.SERVICE_NAME }}' || systemctl is-active ${{ env.SERVICE_NAME }} 2>/dev/null"; then
              echo "‚úÖ Service is running (attempt $i)"
              DEPLOYMENT_SUCCESS=true
              break
            fi
            echo "Attempt $i/5: Waiting for service to start..."
            sleep 10
          done
          
          if [[ "$DEPLOYMENT_SUCCESS" == "true" ]]; then
            echo "‚úÖ ${{ env.SERVICE_NAME }} service deployment completed successfully"
          else
            echo "‚ö†Ô∏è Service deployment may have issues - check server logs"
          fi

  # ============================================================================
  # Health Checks
  # ============================================================================
  health-check:
    name: üè• Health Check
    runs-on: ubuntu-latest
    needs: [preflight-checks, setup-infrastructure, deploy-service]
    if: |
      always() && 
      (needs.preflight-checks.outputs.should_health_check == 'true' || 
       (needs.preflight-checks.outputs.should_deploy == 'true' && needs.deploy-service.result == 'success'))
    
    steps:
      - name: üè• Perform Health Checks
        run: |
          echo "üè• Running comprehensive health checks for ${{ env.SERVICE_NAME }}..."
          
          if [[ -n "${{ needs.setup-infrastructure.outputs.server_ip }}" ]]; then
            SERVER_IP="${{ needs.setup-infrastructure.outputs.server_ip }}"
            TAILSCALE_IP="${{ needs.setup-infrastructure.outputs.tailscale_ip }}"
            
            # Ensure .ssh directory exists and decode SSH key for health checks
            mkdir -p ~/.ssh
            echo "${{ needs.setup-infrastructure.outputs.ssh_private_key }}" | base64 -d > ~/.ssh/deployment_key
            chmod 600 ~/.ssh/deployment_key
            
            # Verify the key was created successfully
            if [[ ! -f ~/.ssh/deployment_key ]]; then
              echo "‚ùå Failed to create SSH deployment key for health checks"
              exit 1
            fi
            echo "‚úÖ SSH deployment key created successfully for health checks"
            
            echo "üîç 1. Basic connectivity tests..."
            # Basic connectivity test
            if ping -c 3 "$SERVER_IP" >/dev/null 2>&1; then
              echo "‚úÖ Server ping successful"
            else
              echo "‚ö†Ô∏è Server ping failed"
            fi
            
            # SSH connectivity test
            if ssh -i ~/.ssh/deployment_key -o StrictHostKeyChecking=no -o ConnectTimeout=10 root@"$SERVER_IP" "echo 'SSH OK'"; then
              echo "‚úÖ SSH connection successful"
            else
              echo "‚ùå SSH connection failed"
              exit 1
            fi
            
            echo "üîç 2. Service health checks..."
            # Check if Docker is running
            DOCKER_STATUS=$(ssh -i ~/.ssh/deployment_key -o StrictHostKeyChecking=no root@"$SERVER_IP" "systemctl is-active docker 2>/dev/null || echo 'inactive'")
            if [[ "$DOCKER_STATUS" == "active" ]]; then
              echo "‚úÖ Docker service is running"
            else
              echo "‚ùå Docker service is not running: $DOCKER_STATUS"
            fi
            
            # Check if Tailscale is connected
            TAILSCALE_STATUS=$(ssh -i ~/.ssh/deployment_key -o StrictHostKeyChecking=no root@"$SERVER_IP" "tailscale status --self --peers=false 2>/dev/null | head -1" || echo "not connected")
            if echo "$TAILSCALE_STATUS" | grep -q "online"; then
              echo "‚úÖ Tailscale is connected"
            else
              echo "‚ö†Ô∏è Tailscale status: $TAILSCALE_STATUS"
            fi
            
            echo "üîç 3. Service-specific health checks..."
            # Check if service containers are running
            RUNNING_CONTAINERS=$(ssh -i ~/.ssh/deployment_key -o StrictHostKeyChecking=no root@"$SERVER_IP" "docker ps --format 'table {{.Names}}\t{{.Status}}' | grep '${{ env.SERVICE_NAME }}' || echo 'none'")
            if [[ "$RUNNING_CONTAINERS" != "none" ]]; then
              echo "‚úÖ Service containers are running:"
              echo "$RUNNING_CONTAINERS"
            else
              echo "‚ö†Ô∏è No service containers found running"
            fi
            
            # Check network connectivity
            echo "üîç 4. Network connectivity tests..."
            # Test HTTP connectivity (if service exposes port 80)
            if timeout 10 curl -s -o /dev/null -w "%{http_code}" "http://$SERVER_IP" | grep -E "^[2-3][0-9][0-9]$"; then
              echo "‚úÖ HTTP service is responding"
            else
              echo "‚ÑπÔ∏è HTTP service not responding on port 80 (may be normal)"
            fi
            
            # Test Tailscale IP connectivity if available
            if [[ "$TAILSCALE_IP" != "pending" && -n "$TAILSCALE_IP" ]]; then
              if timeout 5 ping -c 1 "$TAILSCALE_IP" >/dev/null 2>&1; then
                echo "‚úÖ Tailscale IP is reachable: $TAILSCALE_IP"
              else
                echo "‚ö†Ô∏è Tailscale IP not reachable: $TAILSCALE_IP"
              fi
            fi
            
            echo "üîç 5. Resource health checks..."
            # Check system resources
            SYSTEM_INFO=$(ssh -i ~/.ssh/deployment_key -o StrictHostKeyChecking=no root@"$SERVER_IP" "
              echo 'CPU:' \$(nproc) 'cores'
              echo 'RAM:' \$(free -h | awk '/^Mem:/ {print \$2}' | head -1)
              echo 'Disk:' \$(df -h / | awk 'NR==2 {print \$4}' | head -1) 'free'
              echo 'Uptime:' \$(uptime -p)
            ")
            echo "üìä System resources:"
            echo "$SYSTEM_INFO"
            
            echo "üîç 6. DNS verification checks..."
            # Check if DNS record was updated correctly
            if [[ -n "${{ secrets.CLOUDFLARE_EMAIL }}" && -n "${{ secrets.CLOUDFLARE_API_TOKEN }}" ]]; then
              echo "üåê Verifying DNS record for ${{ env.FULL_DOMAIN }}..."
              
              # Check DNS resolution
              DNS_RESULT=$(dig +short "${{ env.FULL_DOMAIN }}" A 2>/dev/null | head -1 || echo "")
              if [[ -n "$DNS_RESULT" ]]; then
                if [[ "$DNS_RESULT" == "$TAILSCALE_IP" ]]; then
                  echo "‚úÖ DNS record correct: ${{ env.FULL_DOMAIN }} -> $DNS_RESULT"
                else
                  echo "‚ö†Ô∏è DNS record mismatch: ${{ env.FULL_DOMAIN }} -> $DNS_RESULT (expected: $TAILSCALE_IP)"
                  echo "‚ÑπÔ∏è DNS propagation may still be in progress"
                fi
              else
                echo "‚ö†Ô∏è DNS record not found for ${{ env.FULL_DOMAIN }}"
              fi
            else
              echo "‚ÑπÔ∏è Cloudflare credentials not available - skipping DNS verification"
            fi
            
            echo "‚úÖ Health checks completed for ${{ env.SERVICE_NAME }}"
          else
            echo "‚ö†Ô∏è No server IP available for health checks"
          fi

  # ============================================================================
  # Summary Report
  # ============================================================================
  deployment-summary:
    name: üìã Deployment Summary
    runs-on: ubuntu-latest
    needs: [preflight-checks, setup-infrastructure, deploy-service, health-check]
    if: always()
    
    steps:
      - name: üìã Generate Deployment Report
        run: |
          echo "üìã Deployment Summary for ${{ env.SERVICE_NAME }}"
          echo "=================================================="
          echo "üéØ Action: ${{ env.ACTION_TYPE }}"
          echo "üñ•Ô∏è  Server Type: ${{ env.SERVER_TYPE }}"
          echo "üåç Region: ${{ env.TARGET_REGION }}"
          echo "üîó Domain: ${{ env.FULL_DOMAIN }}"
          echo ""
          
          # Job Status Summary
          echo "üìä Job Results:"
          echo "‚úÖ Preflight Checks: ${{ needs.preflight-checks.result }}"
          echo "üèóÔ∏è  Infrastructure: ${{ needs.setup-infrastructure.result }}"
          echo "üöÄ Service Deploy: ${{ needs.deploy-service.result }}"
          echo "üè• Health Check: ${{ needs.health-check.result }}"
          echo ""
          
          # Server Information
          if [[ "${{ needs.setup-infrastructure.result }}" == "success" ]]; then
            echo "üñ•Ô∏è  Server Details:"
            echo "   üìç Public IP: ${{ needs.setup-infrastructure.outputs.server_ip }}"
            echo "   üîó Tailscale IP: ${{ needs.setup-infrastructure.outputs.tailscale_ip }}"
            echo "   üÜî Server ID: ${{ needs.setup-infrastructure.outputs.server_id }}"
            echo ""
          fi
          
          # Overall Status
          if [[ "${{ needs.setup-infrastructure.result }}" == "success" && 
                ("${{ needs.deploy-service.result }}" == "success" || "${{ needs.deploy-service.result }}" == "skipped") ]]; then
            echo "üéâ Overall Status: SUCCESS"
            echo "‚úÖ ${{ env.SERVICE_NAME }} deployment completed successfully!"
          else
            echo "‚ùå Overall Status: FAILED"
            echo "üí• Deployment encountered errors - check job logs for details"
          fi
